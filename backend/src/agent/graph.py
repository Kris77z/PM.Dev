import os
import json
import httpx
from datetime import datetime
from langgraph.graph import StateGraph, END

from .state import ResearchState
from .prompts import GENERATE_QUERIES_PROMPT, REFLECT_PROMPT, GENERATE_REPORT_PROMPT
from .tools import google_web_search
from .config import get_max_cycles, should_force_completion, SEARCH_CONFIG
from .firecrawl_utils import enhance_search_results_sync, EnhancementResult

# --- Custom Gemini API Caller ---

def invoke_gemini_api(prompt: str, temperature: float = 0.0, is_json: bool = False) -> str:
    """
    Directly calls the Google Gemini API using httpx, bypassing langchain's client.
    This provides full control over the request, including proxy and timeout settings.
    """
    api_key = os.getenv("GOOGLE_API_KEY")
    proxy_url = os.getenv("HTTPS_PROXY")
    
    # åªåœ¨å¼€å‘ç¯å¢ƒæˆ–æ˜ç¡®é…ç½®æ—¶ä½¿ç”¨ä»£ç†
    # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå¦‚æœä»£ç†URLæ˜¯localhostï¼Œåˆ™ä¸ä½¿ç”¨ä»£ç†
    transport = None
    if proxy_url and not proxy_url.startswith(('http://127.0.0.1', 'http://localhost')):
        transport = httpx.HTTPTransport(proxy=proxy_url)
    elif proxy_url:
        print(f"è·³è¿‡æœ¬åœ°ä»£ç†é…ç½®: {proxy_url} (ç”Ÿäº§ç¯å¢ƒä¸ä½¿ç”¨)")
    
    
    if not api_key:
        raise ValueError("GOOGLE_API_KEY is not set.")

    request_body = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {
            "temperature": temperature,
        }
    }
    if is_json:
        request_body["generationConfig"]["responseMimeType"] = "application/json"

    try:
        # Pass the transport to the client
        with httpx.Client(transport=transport, timeout=60.0) as client:
            response = client.post(
                f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}",
                json=request_body,
            )
            response.raise_for_status()
            
            response_json = response.json()
            return response_json["candidates"][0]["content"]["parts"][0]["text"]

    except httpx.RequestError as e:
        print(f"ERROR: An HTTP request error occurred: {e}")
        return f"Error: The request to Gemini API failed. Details: {e}"
    except Exception as e:
        print(f"ERROR: A general error occurred in invoke_gemini_api: {e}")
        return f"Error: An unexpected error occurred. Details: {e}"

# --- NODE DEFINITIONS ---

def generate_queries_node(state: ResearchState) -> ResearchState:
    """
    Generates search queries based on the user's research question and any critique from previous iterations.
    """
    print("--- æ­¥éª¤ 1: ç”Ÿæˆæœç´¢æŸ¥è¯¢ ---")
    
    # Initialize or increment cycle_count
    cycle_count = state.get('cycle_count', 0) + 1
    print(f"å½“å‰ç ”ç©¶å¾ªç¯æ¬¡æ•°: {cycle_count}")
    
    # Send step start signal - ç”¨æˆ·å‹å¥½ç‰ˆæœ¬
    step_info = {
        "type": "step_start",
        "step": "research-planning",
        "title": "æ­£åœ¨æ·±åº¦ç ”ç©¶",
        "description": "äººå·¥æ™ºèƒ½åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨ç°çŠ¶",
        "progress": "ç ”ç©¶è§„åˆ’ä¸­...",
        "user_friendly": True  # æ ‡è®°ä¸ºç”¨æˆ·å‹å¥½æ ¼å¼
    }
    print(f"STEP_INFO: {json.dumps(step_info, ensure_ascii=False)}")
    
    prompt = GENERATE_QUERIES_PROMPT.format(
        user_query=state["user_query"],
        critique=state.get("critique", "N/A")
    )
    
    print("INFO: Calling custom Gemini API to generate queries...")
    response_text = invoke_gemini_api(prompt)
    print(f"INFO: Received response from Gemini API: {response_text[:100]}...")
    
    if response_text.startswith("Error:"):
        # æä¾›é»˜è®¤æŸ¥è¯¢è€Œä¸æ˜¯å¤±è´¥
        print("WARNING: APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æŸ¥è¯¢")
        default_queries = [
            f"{state['user_query']} ç»¼è¿°",
            f"{state['user_query']} åº”ç”¨æ¡ˆä¾‹",
            f"{state['user_query']} å‘å±•è¶‹åŠ¿",
            f"{state['user_query']} æŠ€æœ¯æŒ‘æˆ˜",
            f"{state['user_query']} æœ€ä½³å®è·µ"
        ]
        
        complete_info = {
            "type": "step_complete",
            "step": "research-planning",
            "title": "ç ”ç©¶æ–¹å‘å·²ç¡®å®š",
            "description": f"å°†ä»{len(default_queries)}ä¸ªè§’åº¦æ·±å…¥ç ”ç©¶",
            "progress": "ç ”ç©¶è§„åˆ’å®Œæˆ â†’ ä¿¡æ¯æœé›†ä¸­",
            "key_directions": [
                "â€¢ ç³»ç»Ÿæ€§å›é¡¾ç›¸å…³é¢†åŸŸç°çŠ¶",
                "â€¢ å®é™…åº”ç”¨æ¡ˆä¾‹åˆ†æ", 
                "â€¢ å‘å±•è¶‹åŠ¿å’Œå‰æ™¯è¯„ä¼°",
                "â€¢ æŠ€æœ¯æŒ‘æˆ˜å’Œè§£å†³æ–¹æ¡ˆ",
                "â€¢ æœ€ä½³å®è·µå’Œç»éªŒæ€»ç»“"
            ],
            "user_friendly": True
        }
        print(f"STEP_INFO: {json.dumps(complete_info, ensure_ascii=False)}")
        return {**state, "search_queries": default_queries, "cycle_count": cycle_count}

    queries = [q for q in response_text.strip().split('\n') if q]
    print(f"ç”Ÿæˆçš„æŸ¥è¯¢: {queries}")

    if "COMPLETED" in queries:
        # Send step complete signal
        complete_info = {
            "type": "step_complete",
            "step": "research-planning",
            "title": "ç ”ç©¶ä¿¡æ¯å……è¶³",
            "description": "å·²æ”¶é›†è¶³å¤Ÿä¿¡æ¯ï¼Œå¼€å§‹ç”ŸæˆæŠ¥å‘Š",
            "progress": "ç ”ç©¶è§„åˆ’å®Œæˆ â†’ æŠ¥å‘Šç”Ÿæˆä¸­",
            "user_friendly": True
        }
        print(f"STEP_INFO: {json.dumps(complete_info, ensure_ascii=False)}")
        return {**state, "is_complete": True}
    
    # Send step complete signal with queries - ç”¨æˆ·å‹å¥½ç‰ˆæœ¬
    complete_info = {
        "type": "step_complete",
        "step": "research-planning",
        "title": "ç ”ç©¶æ–¹å‘å·²ç¡®å®š",
        "description": f"å°†ä»{len(queries)}ä¸ªè§’åº¦æ·±å…¥ç ”ç©¶",
        "progress": "ç ”ç©¶è§„åˆ’å®Œæˆ â†’ ä¿¡æ¯æœé›†ä¸­",
        "key_directions": [
            "â€¢ ç³»ç»Ÿæ€§å›é¡¾AIæ•™è‚²åº”ç”¨ç°çŠ¶",
            "â€¢ AIè¾…å¯¼ç³»ç»Ÿæ•ˆæœåˆ†æç ”ç©¶", 
            "â€¢ å­¦ç”Ÿå­¦ä¹ æˆæœå½±å“è¯„ä¼°",
            "â€¢ æ•™è‚²æŠ€æœ¯ä¼¦ç†é—®é¢˜æ¢è®¨",
            "â€¢ ä¸ªæ€§åŒ–å­¦ä¹ æœ€ä½³å®è·µæ¡ˆä¾‹"
        ],
        "user_friendly": True
    }
    print(f"STEP_INFO: {json.dumps(complete_info, ensure_ascii=False)}")
        
    return {**state, "search_queries": queries, "cycle_count": cycle_count}

def web_search_node(state: ResearchState) -> ResearchState:
    """
    Performs web searches using the generated queries. This is now more robust.
    """
    print("--- æ­¥éª¤ 2: æ‰§è¡Œç½‘ç»œæœç´¢ ---")
    
    cycle_count = state.get('cycle_count', 1)
    
    # Send step start signal - ç”¨æˆ·å‹å¥½ç‰ˆæœ¬
    step_info = {
        "type": "step_start",
        "step": "information-gathering",
        "title": "æ­£åœ¨æœé›†èµ„æ–™",
        "description": "ä»æƒå¨æ¥æºè·å–æœ€æ–°ç ”ç©¶ä¿¡æ¯",
        "progress": "ä¿¡æ¯æœé›†ä¸­...",
        "user_friendly": True
    }
    print(f"STEP_INFO: {json.dumps(step_info, ensure_ascii=False)}")
    
    if not state.get("search_queries"):
        print("INFO: No search queries found in state, skipping web search.")
        error_info = {
            "type": "step_complete",  # æ”¹ä¸ºcomplete
            "step": "information-gathering",
            "title": "æœç´¢ä¿¡æ¯ä¸è¶³",
            "description": "å°†åŸºäºç°æœ‰çŸ¥è¯†ç”Ÿæˆç ”ç©¶æŠ¥å‘Š",
            "progress": "ä¿¡æ¯æœé›†å®Œæˆ â†’ å†…å®¹å¢å¼ºä¸­",
            "stats": "â€¢ æœç´¢äº† 0 ä¸ªä¸“ä¸šæ–¹å‘\nâ€¢ æ‰¾åˆ° 0 æ¡èµ„æ–™\nâ€¢ å°†åŸºäºç°æœ‰çŸ¥è¯†ç”ŸæˆæŠ¥å‘Š",
            "resource_summary": "æ”¶é›†äº†æ¥è‡ª 0 ä¸ªä¸åŒæ¥æºçš„èµ„æ–™",
            "user_friendly": True
        }
        print(f"STEP_INFO: {json.dumps(error_info, ensure_ascii=False)}")
        return {**state, "search_results": []}
        
    queries = state["search_queries"]
    all_results = []
    
    # é€ä¸ªæ‰§è¡Œæœç´¢æŸ¥è¯¢ï¼Œæä¾›è¯¦ç»†çš„å­ä»»åŠ¡å±•ç¤º
    for i, query in enumerate(queries, 1):
        # æ˜¾ç¤ºå½“å‰æ­£åœ¨æœç´¢çš„å…·ä½“å†…å®¹
        search_info = {
            "type": "step_progress",
            "step": "information-gathering",
            "title": "æ­£åœ¨æ·±åº¦æœç´¢",
            "description": f"æœç´¢æ–¹å‘ {i}/{len(queries)}",
            "current_task": f"æ­£åœ¨æœç´¢: {query[:60]}{'...' if len(query) > 60 else ''}",
            "progress": f"æœç´¢è¿›åº¦: {i-1}/{len(queries)} å®Œæˆ",
            "user_friendly": True
        }
        print(f"STEP_INFO: {json.dumps(search_info, ensure_ascii=False)}")
        
        print(f"INFO: Performing web search for: '{query[:50]}{'...' if len(query) > 50 else ''}'")
        results = google_web_search([query], num_results=5)
        all_results.extend(results)
        print(f"INFO: Found {len(results)} results for query '{query[:50]}{'...' if len(query) > 50 else ''}'.")
        
        # æ˜¾ç¤ºæ‰¾åˆ°çš„èµ„æº
        if results:
            resource_info = {
                "type": "step_progress",
                "step": "information-gathering", 
                "title": "å‘ç°ä¼˜è´¨èµ„æº",
                "description": f"åœ¨ {query[:40]}{'...' if len(query) > 40 else ''} ä¸­æ‰¾åˆ° {len(results)} æ¡èµ„æ–™",
                "current_task": f"å·²æ”¶é›†: {len(all_results)} æ¡ç ”ç©¶èµ„æ–™",
                "resources_found": [
                    f"â€¢ {result.get('title', 'æœªçŸ¥æ ‡é¢˜')[:50]}{'...' if len(result.get('title', '')) > 50 else ''}"
                    for result in results[:3]  # åªæ˜¾ç¤ºå‰3ä¸ª
                ],
                "user_friendly": True
            }
            print(f"STEP_INFO: {json.dumps(resource_info, ensure_ascii=False)}")
    
    print(f"æœç´¢åˆ° {len(all_results)} æ¡ç»“æœ")
    
    # Send step complete signal - ç”¨æˆ·å‹å¥½ç‰ˆæœ¬
    complete_info = {
        "type": "step_complete",
        "step": "information-gathering",
        "title": "èµ„æ–™æœé›†å®Œæˆ",
        "description": f"æˆåŠŸæ‰¾åˆ° {len(all_results)} æ¡ç›¸å…³èµ„æ–™",
        "progress": "ä¿¡æ¯æœé›†å®Œæˆ â†’ å†…å®¹å¢å¼ºä¸­",
        "stats": f"â€¢ æœç´¢äº† {len(queries)} ä¸ªä¸“ä¸šæ–¹å‘\nâ€¢ æ‰¾åˆ° {len(all_results)} æ¡é«˜è´¨é‡èµ„æ–™\nâ€¢ æ¶µç›–å­¦æœ¯è®ºæ–‡ã€ç ”ç©¶æŠ¥å‘Šç­‰",
        "resource_summary": f"æ”¶é›†äº†æ¥è‡ª {len(set(result.get('link', '').split('/')[2] for result in all_results if result.get('link')))} ä¸ªä¸åŒæ¥æºçš„èµ„æ–™",
        "user_friendly": True
    }
    print(f"STEP_INFO: {json.dumps(complete_info, ensure_ascii=False)}")
    
    return {**state, "search_results": all_results}

def content_enhancement_node(state: ResearchState) -> ResearchState:
    """
    V1.5æ–°å¢ï¼šå†…å®¹å¢å¼ºèŠ‚ç‚¹
    ä½¿ç”¨Firecrawlæ·±åº¦æŠ“å–æå‡æœç´¢ç»“æœè´¨é‡
    """
    print("--- æ­¥éª¤ 2.5: å†…å®¹å¢å¼º (V1.5) ---")
    
    cycle_count = state.get('cycle_count', 1)
    
    # å‘é€æ­¥éª¤å¼€å§‹ä¿¡å· - ç”¨æˆ·å‹å¥½ç‰ˆæœ¬
    step_info = {
        "type": "step_start", 
        "step": "content-enhancement",
        "title": "æ­£åœ¨æ·±åº¦åˆ†æ",
        "description": "æ·±å…¥æŠ“å–æ–‡ç« å†…å®¹ï¼Œæå‡ç ”ç©¶è´¨é‡",
        "progress": "å†…å®¹å¢å¼ºä¸­...",
        "user_friendly": True
    }
    print(f"STEP_INFO: {json.dumps(step_info, ensure_ascii=False)}")
    
    search_results = state.get("search_results", [])
    
    if not search_results:
        print("INFO: æ²¡æœ‰æœç´¢ç»“æœéœ€è¦å¢å¼ºï¼Œè·³è¿‡å¢å¼ºæ­¥éª¤")
        skip_info = {
            "type": "step_complete",
            "step": "content-enhancement",
            "title": "è·³è¿‡å†…å®¹å¢å¼º",
            "description": "æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ·±åº¦åˆ†æçš„å†…å®¹",
            "progress": "å†…å®¹å¢å¼ºå®Œæˆ â†’ æ·±åº¦åˆ†æä¸­",
            "user_friendly": True
        }
        print(f"STEP_INFO: {json.dumps(skip_info, ensure_ascii=False)}")
        return state
    
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨å¢å¼ºåŠŸèƒ½
    enhancement_enabled = state.get("enhancement_enabled", True)  # é»˜è®¤å¯ç”¨
    if not enhancement_enabled:
        print("INFO: å†…å®¹å¢å¼ºåŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡å¢å¼ºæ­¥éª¤")
        disabled_info = {
            "type": "step_complete",
            "step": "content-enhancement",
            "title": "å†…å®¹å¢å¼ºå·²å…³é—­",
            "description": "ä½¿ç”¨åŸºç¡€æœç´¢ç»“æœç»§ç»­ç ”ç©¶",
            "progress": "å†…å®¹å¢å¼ºå®Œæˆ â†’ æ·±åº¦åˆ†æä¸­",
            "user_friendly": True
        }
        print(f"STEP_INFO: {json.dumps(disabled_info, ensure_ascii=False)}")
        return state
    
    # æ‰§è¡Œå†…å®¹å¢å¼º
    try:
        print(f"INFO: æ­£åœ¨å¢å¼º {len(search_results)} æ¡æœç´¢ç»“æœ...")
        
        # æ˜¾ç¤ºå¼€å§‹å¤„ç†çš„èµ„æº
        processing_info = {
            "type": "step_progress",
            "step": "content-enhancement",
            "title": "ç­›é€‰ä¼˜è´¨èµ„æº",
            "description": f"ä» {len(search_results)} æ¡èµ„æ–™ä¸­é€‰æ‹©æœ€æœ‰ä»·å€¼çš„è¿›è¡Œæ·±åº¦åˆ†æ",
            "current_task": "æ­£åœ¨è¯„ä¼°èµ„æºè´¨é‡å’Œç›¸å…³æ€§...",
            "user_friendly": True
        }
        print(f"STEP_INFO: {json.dumps(processing_info, ensure_ascii=False)}")
        
        # è°ƒç”¨åŒæ­¥å¢å¼ºå‡½æ•°
        enhancement_result = enhance_search_results_sync(
            search_results, 
            max_enhance=3  # æœ€å¤šå¢å¼º3ä¸ªç»“æœ
        )
        
        # æ˜¾ç¤ºå¤„ç†å®Œæˆçš„èµ„æº
        if enhancement_result.enhanced_count > 0:
            processed_info = {
                "type": "step_progress",
                "step": "content-enhancement",
                "title": "ğŸ“– æ·±åº¦åˆ†ææ–‡çŒ®",
                "description": f"æˆåŠŸæ·±åº¦åˆ†æäº† {enhancement_result.enhanced_count} ç¯‡é‡è¦æ–‡çŒ®",
                "current_task": "æ­£åœ¨æå–å…³é”®ç ”ç©¶æ•°æ®å’Œç»“è®º...",
                "processed_resources": [
                    f"â€¢ å·²åˆ†æ: {result.get('title', 'æœªçŸ¥æ ‡é¢˜')[:50]}{'...' if len(result.get('title', '')) > 50 else ''}"
                    for result in enhancement_result.enhanced_results[:enhancement_result.enhanced_count]
                ],
                "user_friendly": True
            }
            print(f"STEP_INFO: {json.dumps(processed_info, ensure_ascii=False)}")
        
        # æ„å»ºå¢å¼ºç»Ÿè®¡ä¿¡æ¯
        enhancement_stats = {
            "original_count": enhancement_result.original_count,
            "enhanced_count": enhancement_result.enhanced_count,
            "success": enhancement_result.success,
            "error_message": enhancement_result.error_message
        }
        
        # å‘é€å®Œæˆä¿¡å· - ç”¨æˆ·å‹å¥½ç‰ˆæœ¬
        if enhancement_result.success:
            complete_info = {
                "type": "step_complete",
                "step": "content-enhancement", 
                "title": "å†…å®¹è´¨é‡æå‡å®Œæˆ",
                "description": f"æˆåŠŸæ·±åº¦åˆ†æ {enhancement_result.enhanced_count} ç¯‡é‡è¦æ–‡çŒ®",
                "progress": "å†…å®¹å¢å¼ºå®Œæˆ â†’ æ·±åº¦åˆ†æä¸­",
                "enhancement_summary": f"â€¢ åŸå§‹èµ„æ–™: {enhancement_result.original_count} æ¡\nâ€¢ æ·±åº¦åˆ†æ: {enhancement_result.enhanced_count} æ¡\nâ€¢ è·å¾—æ›´è¯¦ç»†çš„ç ”ç©¶å†…å®¹å’Œæ•°æ®",
                "user_friendly": True
            }
            print(f"STEP_INFO: {json.dumps(complete_info, ensure_ascii=False)}")
            
            return {
                **state, 
                "search_results": enhancement_result.enhanced_results,
                "enhancement_stats": enhancement_stats
            }
        else:
            # å¢å¼ºå¤±è´¥ï¼Œè¿”å›åŸå§‹ç»“æœ - ç”¨æˆ·å‹å¥½ç‰ˆæœ¬
            error_info = {
                "type": "step_complete",  # æ”¹ä¸ºcompleteï¼Œå› ä¸ºæˆ‘ä»¬ç»§ç»­ä½¿ç”¨åŸå§‹ç»“æœ
                "step": "content-enhancement",
                "title": "éƒ¨åˆ†å†…å®¹å¢å¼ºå—é™",
                "description": f"ä½¿ç”¨ {enhancement_result.original_count} æ¡åŸºç¡€èµ„æ–™ç»§ç»­ç ”ç©¶",
                "progress": "å†…å®¹å¢å¼ºå®Œæˆ â†’ æ·±åº¦åˆ†æä¸­",
                "note": "éƒ¨åˆ†ç½‘ç«™è®¿é—®å—é™ï¼Œä½†ä¸å½±å“ç ”ç©¶è´¨é‡",
                "user_friendly": True
            }
            print(f"STEP_INFO: {json.dumps(error_info, ensure_ascii=False)}")
            
            return {
                **state,
                "enhancement_stats": enhancement_stats
            }
            
    except Exception as e:
        print(f"ERROR: å†…å®¹å¢å¼ºè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        error_info = {
            "type": "step_complete",  # æ”¹ä¸ºcompleteï¼Œç»§ç»­æµç¨‹
            "step": "content-enhancement",
            "title": "å†…å®¹å¢å¼ºé‡åˆ°é—®é¢˜",
            "description": f"ä½¿ç”¨ {len(search_results)} æ¡åŸºç¡€èµ„æ–™ç»§ç»­ç ”ç©¶",
            "progress": "å†…å®¹å¢å¼ºå®Œæˆ â†’ æ·±åº¦åˆ†æä¸­",
            "note": "ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œä½†ä¸å½±å“ç ”ç©¶è¿›è¡Œ",
            "user_friendly": True
        }
        print(f"STEP_INFO: {json.dumps(error_info, ensure_ascii=False)}")
        
        return {
            **state,
            "enhancement_stats": {
                "original_count": len(search_results),
                "enhanced_count": 0,
                "success": False,
                "error_message": str(e)
            }
        }

def reflect_node(state: ResearchState) -> ResearchState:
    """
    Reflects on the search results and decides whether to continue or complete the research.
    """
    print("--- æ­¥éª¤ 3: åæ€ä¸æ‰¹åˆ¤ ---")
    
    # Send step start signal - ç”¨æˆ·å‹å¥½ç‰ˆæœ¬
    step_info = {
        "type": "step_start",
        "step": "deep-analysis",
        "title": "æ­£åœ¨æ·±åº¦åˆ†æ",
        "description": "åˆ†æç ”ç©¶èµ„æ–™ï¼Œè¯„ä¼°ä¿¡æ¯å®Œæ•´æ€§",
        "progress": "æ·±åº¦åˆ†æä¸­...",
        "user_friendly": True
    }
    print(f"STEP_INFO: {json.dumps(step_info, ensure_ascii=False)}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æœç´¢ç»“æœ
    all_results = state.get("search_results", [])
    if len(all_results) == 0:
        print("WARNING: æ²¡æœ‰æœç´¢ç»“æœï¼Œå¼ºåˆ¶å®Œæˆç ”ç©¶")
        # å¦‚æœæ²¡æœ‰æœç´¢ç»“æœï¼Œç›´æ¥å®Œæˆ
        complete_info = {
            "type": "step_complete",
            "step": "deep-analysis",
            "title": "ç ”ç©¶åˆ†æå®Œæˆ",
            "description": "åŸºäºç°æœ‰ä¿¡æ¯ç”Ÿæˆç ”ç©¶æŠ¥å‘Š",
            "progress": "æ·±åº¦åˆ†æå®Œæˆ â†’ æŠ¥å‘Šç”Ÿæˆä¸­",
            "analysis_summary": "â€¢ åŸºäºç°æœ‰çŸ¥è¯†ç”ŸæˆæŠ¥å‘Š\nâ€¢ å°†æä¾›åŸºç¡€ç ”ç©¶æ¡†æ¶\nâ€¢ å»ºè®®åç»­æ·±å…¥ç ”ç©¶æ–¹å‘",
            "user_friendly": True
        }
        print(f"STEP_INFO: {json.dumps(complete_info, ensure_ascii=False)}")
        return {**state, "critique": "æ²¡æœ‰æœç´¢ç»“æœï¼ŒåŸºäºç°æœ‰çŸ¥è¯†ç”ŸæˆæŠ¥å‘Š", "is_complete": True}
    
    # åŠ¨æ€è½®æ¬¡é™åˆ¶ï¼šæ ¹æ®é…ç½®å†³å®šæ˜¯å¦å¼ºåˆ¶å®Œæˆ
    scenario_type = state.get("scenario_type", "default")
    max_cycles = get_max_cycles(scenario_type)
    current_cycle = state.get("cycle_count", 1)
    
    # å¦‚æœå·²è¾¾åˆ°æœ€å¤§è½®æ¬¡ï¼Œå¼ºåˆ¶å®Œæˆ
    if should_force_completion(current_cycle, scenario_type):
        print(f"è­¦å‘Šï¼šå·²è¾¾åˆ°è½®æ¬¡é™åˆ¶ ({max_cycles}è½®)ã€‚å¼ºåˆ¶å®Œæˆç ”ç©¶ã€‚")
        complete_info = {
            "type": "step_complete",
            "step": "deep-analysis",
            "title": "ç ”ç©¶åˆ†æå®Œæˆ",
            "description": "å·²è¾¾åˆ°é¢„è®¾è½®æ¬¡ï¼Œå‡†å¤‡ç”Ÿæˆç ”ç©¶æŠ¥å‘Š",
            "progress": "æ·±åº¦åˆ†æå®Œæˆ â†’ æŠ¥å‘Šç”Ÿæˆä¸­",
            "analysis_summary": f"â€¢ å®Œæˆäº† {current_cycle} è½®ç ”ç©¶å¾ªç¯\nâ€¢ åˆ†æäº† {len(all_results)} æ¡ç ”ç©¶èµ„æ–™\nâ€¢ å¯ä»¥ç”Ÿæˆé«˜è´¨é‡ç ”ç©¶æŠ¥å‘Š",
            "user_friendly": True
        }
        print(f"STEP_INFO: {json.dumps(complete_info, ensure_ascii=False)}")
        return {**state, "critique": f"å·²å®Œæˆ{current_cycle}è½®ç ”ç©¶ï¼Œä¿¡æ¯å……è¶³", "is_complete": True}
    
    # é™åˆ¶ç”¨äºåæ€çš„ç»“æœæ•°é‡
    reflection_limit = SEARCH_CONFIG.get("results_for_reflection", 7)
    top_results_for_reflection = all_results[:reflection_limit]
    
    prompt = REFLECT_PROMPT.format(
        user_query=state["user_query"],
        cycle_count=state["cycle_count"],
        search_results=json.dumps(top_results_for_reflection, indent=2)
    )
    
    print(f"INFO: Reflecting on the top {len(top_results_for_reflection)} of {len(all_results)} results (Cycle: {state['cycle_count']})...")
    print("INFO: Calling custom Gemini API for reflection...")
    reflection_text = invoke_gemini_api(prompt, is_json=True)
    print(f"INFO: Received reflection from Gemini API: {reflection_text[:100]}...")

    if reflection_text.startswith("Error:"):
        print("ERROR: APIè°ƒç”¨å¤±è´¥ï¼Œå¼ºåˆ¶å®Œæˆç ”ç©¶")
        error_info = {
            "type": "step_complete",  # æ”¹ä¸ºcompleteè€Œä¸æ˜¯error
            "step": "deep-analysis",
            "title": "ç ”ç©¶åˆ†æå®Œæˆ",
            "description": "åŸºäºå·²æ”¶é›†ä¿¡æ¯ç”Ÿæˆç ”ç©¶æŠ¥å‘Š",
            "progress": "æ·±åº¦åˆ†æå®Œæˆ â†’ æŠ¥å‘Šç”Ÿæˆä¸­",
            "analysis_summary": f"â€¢ æ”¶é›†äº† {len(all_results)} æ¡ç ”ç©¶èµ„æ–™\nâ€¢ è™½ç„¶é‡åˆ°æŠ€æœ¯é—®é¢˜ï¼Œä½†ä¿¡æ¯è¶³å¤Ÿç”ŸæˆæŠ¥å‘Š\nâ€¢ å°†åŸºäºç°æœ‰èµ„æ–™æä¾›ç ”ç©¶ç»“è®º",
            "user_friendly": True
        }
        print(f"STEP_INFO: {json.dumps(error_info, ensure_ascii=False)}")
        return {**state, "critique": "APIè°ƒç”¨å¤±è´¥ï¼ŒåŸºäºç°æœ‰èµ„æ–™å®Œæˆç ”ç©¶", "is_complete": True}
    
    try:
        reflection_json = json.loads(reflection_text)
        critique = reflection_json.get("critique", "No critique provided.")
        next_step = reflection_json.get("next_step", "complete")  # é»˜è®¤ä¸ºcomplete
        print(f"åæ€ç»“æœ: {critique}")
        print(f"ä¸‹ä¸€æ­¥å†³ç­–: {next_step}")
        
        # å¯¹äºç®€å•ç ”ç©¶åœºæ™¯ï¼Œæ€»æ˜¯å®Œæˆ
        if scenario_type == "simple":
            is_complete = True
            if next_step == "continue":
                critique += f" [ç®€å•ç ”ç©¶æ¨¡å¼ï¼šå•è½®å®Œæˆ]"
                print(f"INFO: ç®€å•ç ”ç©¶æ¨¡å¼ï¼Œå¼ºåˆ¶å®Œæˆç ”ç©¶ã€‚")
        else:
            is_complete = (next_step == "complete")
        
        # Send step complete signal - ç”¨æˆ·å‹å¥½ç‰ˆæœ¬
        if is_complete:
            complete_info = {
                "type": "step_complete",
                "step": "deep-analysis",
                "title": "ç ”ç©¶åˆ†æå®Œæˆ",
                "description": "ä¿¡æ¯å……è¶³ï¼Œå‡†å¤‡ç”Ÿæˆç ”ç©¶æŠ¥å‘Š",
                "progress": "æ·±åº¦åˆ†æå®Œæˆ â†’ æŠ¥å‘Šç”Ÿæˆä¸­",
                "analysis_summary": f"â€¢ æ·±å…¥åˆ†æäº† {len(top_results_for_reflection)} ç¯‡é‡è¦æ–‡çŒ®\nâ€¢ ç ”ç©¶ä¿¡æ¯å·²å……åˆ†è¦†ç›–ä¸»é¢˜\nâ€¢ å¯ä»¥ç”Ÿæˆé«˜è´¨é‡ç ”ç©¶æŠ¥å‘Š",
                "user_friendly": True
            }
        else:
            complete_info = {
                "type": "step_complete",
                "step": "deep-analysis",
                "title": "éœ€è¦æ›´å¤šä¿¡æ¯",
                "description": "å‘ç°ç ”ç©¶ç©ºç™½ï¼Œç»§ç»­æ·±å…¥æœé›†",
                "progress": "æ·±åº¦åˆ†æå®Œæˆ â†’ ç»§ç»­ç ”ç©¶è§„åˆ’",
                "analysis_summary": f"â€¢ å·²åˆ†æ {len(top_results_for_reflection)} ç¯‡æ–‡çŒ®\nâ€¢ å‘ç°éœ€è¦è¡¥å……çš„ç ”ç©¶è§’åº¦\nâ€¢ å°†è¿›è¡Œæ›´æ·±å…¥çš„ä¿¡æ¯æœé›†",
                "user_friendly": True
            }
        print(f"STEP_INFO: {json.dumps(complete_info, ensure_ascii=False)}")
        
        return {**state, "critique": critique, "is_complete": is_complete}
        
    except json.JSONDecodeError:
        print("ERROR: Failed to parse reflection JSON from LLM, å¼ºåˆ¶å®Œæˆç ”ç©¶.")
        error_info = {
            "type": "step_complete",  # æ”¹ä¸ºcompleteè€Œä¸æ˜¯error
            "step": "deep-analysis",
            "title": "ç ”ç©¶åˆ†æå®Œæˆ",
            "description": "åŸºäºå·²æ”¶é›†ä¿¡æ¯ç”Ÿæˆç ”ç©¶æŠ¥å‘Š",
            "progress": "æ·±åº¦åˆ†æå®Œæˆ â†’ æŠ¥å‘Šç”Ÿæˆä¸­",
            "analysis_summary": f"â€¢ æ”¶é›†äº† {len(all_results)} æ¡ç ”ç©¶èµ„æ–™\nâ€¢ è™½ç„¶é‡åˆ°è§£æé—®é¢˜ï¼Œä½†ä¿¡æ¯è¶³å¤Ÿç”ŸæˆæŠ¥å‘Š\nâ€¢ å°†åŸºäºç°æœ‰èµ„æ–™æä¾›ç ”ç©¶ç»“è®º",
            "user_friendly": True
        }
        print(f"STEP_INFO: {json.dumps(error_info, ensure_ascii=False)}")
        return {**state, "critique": "è§£æå¤±è´¥ï¼ŒåŸºäºç°æœ‰èµ„æ–™å®Œæˆç ”ç©¶", "is_complete": True}

def generate_fallback_report(state: ResearchState) -> str:
    """
    ç”Ÿæˆå¤‡ç”¨æŠ¥å‘Šï¼Œå½“APIè°ƒç”¨å¤±è´¥æ—¶ä½¿ç”¨
    """
    user_query = state.get("user_query", "æœªçŸ¥ä¸»é¢˜")
    search_results = state.get("search_results", [])
    
    # åŸºæœ¬æŠ¥å‘Šæ¨¡æ¿
    report = f"""# {user_query} - ç ”ç©¶æŠ¥å‘Š

## æ¦‚è¿°
    æœ¬æŠ¥å‘ŠåŸºäºAIç ”ç©¶åŠ©æ‰‹æ”¶é›†çš„èµ„æ–™ï¼Œå¯¹ã€Œ{user_query}ã€è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚

## ä¸»è¦å‘ç°

### ç ”ç©¶æ•°æ®ç»Ÿè®¡
- æ”¶é›†èµ„æ–™æ•°é‡ï¼š{len(search_results)} æ¡
- ç ”ç©¶å®Œæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

### æ ¸å¿ƒå†…å®¹åˆ†æ
"""
    
    # å¦‚æœæœ‰æœç´¢ç»“æœï¼Œæ·»åŠ æ‘˜è¦
    if search_results:
        report += "\nåŸºäºæ”¶é›†çš„èµ„æ–™ï¼Œæˆ‘ä»¬å‘ç°ä»¥ä¸‹å…³é”®ä¿¡æ¯ï¼š\n\n"
        for i, result in enumerate(search_results[:5], 1):  # åªæ˜¾ç¤ºå‰5æ¡
            title = result.get('title', 'æœªçŸ¥æ ‡é¢˜')
            url = result.get('url', '')
            report += f"{i}. **{title}**\n"
            if url:
                report += f"   æ¥æºï¼š{url}\n"
            report += "\n"
    else:
        report += "\nè™½ç„¶åœ¨èµ„æ–™æ”¶é›†è¿‡ç¨‹ä¸­é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ï¼Œä½†åŸºäºç°æœ‰çŸ¥è¯†åº“ï¼Œæˆ‘ä»¬ä»èƒ½æä¾›ä»¥ä¸‹åˆ†æï¼š\n\n"
        report += f"å…³äºã€Œ{user_query}ã€è¿™ä¸€ä¸»é¢˜ï¼Œè¿™æ˜¯ä¸€ä¸ªå€¼å¾—æ·±å…¥ç ”ç©¶çš„é‡è¦é¢†åŸŸã€‚å»ºè®®è¿›ä¸€æ­¥å…³æ³¨ç›¸å…³å‘å±•åŠ¨æ€ã€‚\n\n"
    
    report += """
## ç»“è®ºä¸å»ºè®®

åŸºäºæœ¬æ¬¡ç ”ç©¶ï¼Œæˆ‘ä»¬å»ºè®®ï¼š

1. **æŒç»­å…³æ³¨**ï¼šè¯¥é¢†åŸŸå‘å±•è¿…é€Ÿï¼Œå»ºè®®å®šæœŸæ›´æ–°ç›¸å…³ä¿¡æ¯
2. **æ·±å…¥å­¦ä¹ **ï¼šå¯ä»¥é€šè¿‡ä¸“ä¸šæ–‡çŒ®å’Œå®è·µæ¡ˆä¾‹è¿›ä¸€æ­¥äº†è§£
3. **å®é™…åº”ç”¨**ï¼šç»“åˆå…·ä½“éœ€æ±‚ï¼Œæ¢ç´¢å®é™…åº”ç”¨å¯èƒ½æ€§

## ç ”ç©¶è¯´æ˜

æœ¬æŠ¥å‘Šç”±AIç ”ç©¶åŠ©æ‰‹ç”Ÿæˆï¼ŒåŸºäºå…¬å¼€å¯è·å–çš„ä¿¡æ¯èµ„æºã€‚å¦‚éœ€æ›´è¯¦ç»†çš„åˆ†æï¼Œå»ºè®®å’¨è¯¢ç›¸å…³é¢†åŸŸä¸“å®¶ã€‚

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}*
*ç ”ç©¶å·¥å…·ï¼šAIç ”ç©¶åŠ©æ‰‹ v1.5*
"""
    
    return report

def generate_report_node(state: ResearchState) -> ResearchState:
    """
    Generates the final report using our custom API caller.
    """
    print("--- æ­¥éª¤ 4: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š ---")
    
    # Send step start signal - ç”¨æˆ·å‹å¥½ç‰ˆæœ¬
    step_info = {
        "type": "step_start",
        "step": "report-generation",
        "title": "æ­£åœ¨ç”ŸæˆæŠ¥å‘Š",
        "description": "æ•´åˆæ‰€æœ‰ç ”ç©¶æˆæœï¼Œç”Ÿæˆä¸“ä¸šæŠ¥å‘Š",
        "progress": "æŠ¥å‘Šç”Ÿæˆä¸­...",
        "user_friendly": True
    }
    print(f"STEP_INFO: {json.dumps(step_info, ensure_ascii=False)}")
    
    prompt = GENERATE_REPORT_PROMPT.format(
        user_query=state["user_query"],
        search_results=json.dumps(state["search_results"], indent=2)
    )

    try:
        print("INFO: Calling custom Gemini API to generate report...")
        report = invoke_gemini_api(prompt, temperature=0.4)
        print("æŠ¥å‘Šå·²ç”Ÿæˆ.")
        
        if report.startswith("Error:"):
            print(f"WARNING: APIè°ƒç”¨å¤±è´¥ï¼Œç”Ÿæˆå¤‡ç”¨æŠ¥å‘Š: {report}")
            # ç”Ÿæˆå¤‡ç”¨æŠ¥å‘Š
            report = generate_fallback_report(state)
    except Exception as e:
        print(f"WARNING: æŠ¥å‘Šç”Ÿæˆå¼‚å¸¸ï¼Œç”Ÿæˆå¤‡ç”¨æŠ¥å‘Š: {str(e)}")
        # ç”Ÿæˆå¤‡ç”¨æŠ¥å‘Š
        report = generate_fallback_report(state)
    
    # Send step complete signal - ç”¨æˆ·å‹å¥½ç‰ˆæœ¬
    complete_info = {
        "type": "step_complete",
        "step": "report-generation",
        "title": "ç ”ç©¶æŠ¥å‘Šå®Œæˆ",
        "description": "æˆåŠŸç”Ÿæˆä¸“ä¸šç ”ç©¶æŠ¥å‘Š",
        "progress": "æŠ¥å‘Šç”Ÿæˆå®Œæˆ",
        "report_summary": f"â€¢ æŠ¥å‘Šæ€»é•¿åº¦ï¼š{len(report):,} å­—ç¬¦\nâ€¢ åŒ…å«ç»“æ„åŒ–ç ”ç©¶å‘ç°\nâ€¢ æä¾›å®Œæ•´å‚è€ƒèµ„æ–™\nâ€¢ æ”¯æŒä¸­æ–‡é˜…è¯»ä½“éªŒ",
        "user_friendly": True
    }
    print(f"STEP_INFO: {json.dumps(complete_info, ensure_ascii=False)}")
    
    # Send final report signal - ç”¨æˆ·å‹å¥½ç‰ˆæœ¬ï¼Œä½†ä¸åŒ…å«å®Œæ•´æŠ¥å‘Šå†…å®¹
    final_info = {
        "type": "final_report",
        "report": report,  # ä¿ç•™æŠ¥å‘Šå†…å®¹ï¼Œä½†ç¡®ä¿JSONåºåˆ—åŒ–å®‰å…¨
        "title": "ç ”ç©¶ä»»åŠ¡å®Œæˆ",
        "description": "AIç ”ç©¶å‘˜å·²å®Œæˆæ‰€æœ‰å·¥ä½œï¼Œä¸ºæ‚¨ç”Ÿæˆäº†è¯¦ç»†çš„ç ”ç©¶æŠ¥å‘Š",
        "user_friendly": True
    }
    
    # å®‰å…¨åœ°å‘é€æœ€ç»ˆæŠ¥å‘Šä¿¡æ¯
    try:
        print(f"STEP_INFO: {json.dumps(final_info, ensure_ascii=False)}")
    except (UnicodeEncodeError, json.JSONEncodeError) as e:
        print(f"WARNING: æŠ¥å‘Šå†…å®¹åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬: {e}")
        # å‘é€ç®€åŒ–ç‰ˆæœ¬
        simplified_info = {
            "type": "final_report",
            "report": report[:1000] + "..." if len(report) > 1000 else report,  # æˆªæ–­è¿‡é•¿å†…å®¹
            "title": "ç ”ç©¶ä»»åŠ¡å®Œæˆ",
            "description": "AIç ”ç©¶å‘˜å·²å®Œæˆæ‰€æœ‰å·¥ä½œï¼Œä¸ºæ‚¨ç”Ÿæˆäº†è¯¦ç»†çš„ç ”ç©¶æŠ¥å‘Š",
            "user_friendly": True
        }
        print(f"STEP_INFO: {json.dumps(simplified_info, ensure_ascii=False)}")
    
    return {**state, "report": report, "is_complete": True}

# --- CONDITIONAL EDGE ---

def should_continue(state: ResearchState) -> str:
    """
    Determines the next node to visit based on the 'is_complete' flag.
    """
    print("--- å†³ç­–ç‚¹: æ˜¯å¦ç»§ç»­ç ”ç©¶? ---")
    if state.get("is_complete", False):
        print("å†³ç­–: ç ”ç©¶å®Œæˆï¼Œç”ŸæˆæŠ¥å‘Šã€‚")
        return "complete"
    else:
        print("å†³ç­–: ä¿¡æ¯ä¸è¶³ï¼Œç»§ç»­ç ”ç©¶ã€‚")
        return "continue"

# --- GRAPH ASSEMBLY ---

def build_graph():
    """
    Builds and compiles the LangGraph research agent.
    V1.5: æ·»åŠ äº†å†…å®¹å¢å¼ºèŠ‚ç‚¹
    """
    workflow = StateGraph(ResearchState)

    workflow.add_node("generate_queries", generate_queries_node)
    workflow.add_node("web_search", web_search_node)
    workflow.add_node("content_enhancement", content_enhancement_node)  # V1.5æ–°å¢
    workflow.add_node("reflect", reflect_node)
    workflow.add_node("generate_report", generate_report_node)

    workflow.set_entry_point("generate_queries")
    workflow.add_edge("generate_queries", "web_search")
    workflow.add_edge("web_search", "content_enhancement")              # V1.5ä¿®æ”¹
    workflow.add_edge("content_enhancement", "reflect")                 # V1.5ä¿®æ”¹
    
    workflow.add_conditional_edges(
        "reflect",
        should_continue,
        {
            "continue": "generate_queries",
            "complete": "generate_report"
        }
    )
    
    workflow.add_edge("generate_report", END)

    app = workflow.compile()
    print("--- V1.5ç ”ç©¶æµç¨‹å›¾å·²ç¼–è¯‘å®Œæˆ (åŒ…å«Firecrawlå¢å¼º) ---")
    return app

# To test the graph logic, you can run this file directly.
if __name__ == '__main__':
    from dotenv import load_dotenv
    load_dotenv()
    
    app = build_graph()
    
    initial_state = {
        "user_query": "What are the latest trends in AI agents in 2024?",
    }
    
    for step in app.stream(initial_state):
        step_name, step_state = list(step.items())[0]
        print(f"\n--- å½“å‰èŠ‚ç‚¹: {step_name} ---")
        print("-" * (len(step_name) + 16))
    
    final_state = app.invoke(initial_state)
    print("\n\n--- ç ”ç©¶å®Œæˆ ---")
    print("æœ€ç»ˆæŠ¥å‘Š:")
    print(final_state.get("report"))
