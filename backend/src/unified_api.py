"""
ç»Ÿä¸€APIå…¥å£
æ”¯æŒV1ï¼ˆç°æœ‰ï¼‰å’ŒV2ï¼ˆé«˜çº§ï¼‰ä¸¤ç§LangGraphæ¶æ„
"""

from typing import Dict, Any, Iterator, Optional
from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import json
import asyncio
from langchain_core.runnables import RunnableConfig

# V1æ¶æ„å¯¼å…¥
from agent.graph import build_graph
from agent.state import ResearchState as V1State

# V2æ¶æ„å¯¼å…¥
from agents_v2.advanced_graph import get_advanced_research_graph
from agents_v2.advanced_state import AdvancedResearchState as V2State


class UnifiedResearchRequest(BaseModel):
    """ç»Ÿä¸€ç ”ç©¶è¯·æ±‚"""
    query: str
    version: str = "v1"  # "v1" æˆ– "v2"
    scenario_type: str = "default"  # v1å…¼å®¹
    mode: str = "research_assistant"  # v2æ¨¡å¼ï¼šresearch_assistant, quick_lookup, deep_research
    research_mode: Optional[str] = None  # v2å…¼å®¹å­—æ®µ


class APIManager:
    """APIç®¡ç†å™¨"""
    
    def __init__(self):
        self.v1_graph = None
        self.v2_graph = None
    
    def get_v1_graph(self):
        """è·å–V1å›¾å®ä¾‹"""
        if not self.v1_graph:
            self.v1_graph = build_graph()
        return self.v1_graph
    
    def get_v2_graph(self):
        """è·å–V2å›¾å®ä¾‹"""
        if not self.v2_graph:
            self.v2_graph = get_advanced_research_graph()
        return self.v2_graph
    
    def create_v1_initial_state(self, query: str, scenario_type: str) -> V1State:
        """åˆ›å»ºV1åˆå§‹çŠ¶æ€"""
        return {
            "user_query": query,
            "scenario_type": scenario_type,
            "search_queries": [],
            "search_results": [],
            "critique": "",
            "report": "",
            "is_complete": False,
            "cycle_count": 0
        }
    
    def create_v2_initial_state(self, query: str, mode: str) -> V2State:
        """åˆ›å»ºV2åˆå§‹çŠ¶æ€"""
        return {
            # æ ¸å¿ƒç ”ç©¶ä¿¡æ¯
            "user_query": query,
            "research_plan": [],
            "current_task_pointer": 0,
            "total_estimated_cycles": 0,
            
            # å¤šä»»åŠ¡åè°ƒ
            "task_results": [],
            "global_memory": [],
            "completed_tasks": [],
            "failed_tasks": [],
            
            # æœç´¢å’Œå¤„ç†
            "executed_search_queries": [],
            "web_research_results": [],
            "sources_gathered": [],
            "parallel_search_results": [],
            
            # åæ€å’Œè¯„ä¼°
            "reflection_is_sufficient": None,
            "reflection_knowledge_gap": None,
            "reflection_follow_up_queries": None,
            "reflection_quality_score": None,
            
            # æ™ºèƒ½å¢å¼ºç³»ç»Ÿ
            "enhancement_decision": None,
            "enhancement_status": None,
            "enhanced_content_results": None,
            "enhanced_sources_count": None,
            "enhancement_quality_boost": None,
            "enhancement_error": None,
            
            # æ‰§è¡Œæ§åˆ¶
            "max_research_loops_per_task": 4,
            "current_task_loop_count": 0,
            "total_research_loops": 0,
            "reasoning_model": "gemini-1.5-flash",
            
            # ä»»åŠ¡ç‰¹å®šç»“æœ
            "current_task_detailed_findings": [],
            "task_specific_results": [],
            
            # æœ€ç»ˆè¾“å‡º
            "final_report_markdown": None,
            "execution_summary": None,
            
            # é”™è¯¯å¤„ç†
            "last_error": None,
            "error_recovery_attempts": 0,
            
            # V1å…¼å®¹æ€§å­—æ®µ
            "search_queries": [],
            "search_results": [],
            "critique": "",
            "report": "",
            "is_complete": False,
            "cycle_count": 0,
            "scenario_type": mode
        }
    
    async def execute_v1_research(
        self, 
        query: str, 
        scenario_type: str
    ) -> Iterator[Dict[str, Any]]:
        """æ‰§è¡ŒV1ç ”ç©¶æµç¨‹"""
        
        print(f"ğŸ”„ å¯åŠ¨V1ç ”ç©¶æµç¨‹ï¼š{query}")
        
        graph = self.get_v1_graph()
        initial_state = self.create_v1_initial_state(query, scenario_type)
        
        config = RunnableConfig(
            configurable={
                "thread_id": "v1-research",
            }
        )
        
        try:
            async for event in graph.astream(initial_state, config):
                yield {
                    "version": "v1",
                    "event_type": "state_update",
                    "data": event,
                    "timestamp": "now"
                }
                
                # æ£€æŸ¥å®ŒæˆçŠ¶æ€
                if any(state.get("is_complete", False) for state in event.values()):
                    yield {
                        "version": "v1",
                        "event_type": "completion",
                        "data": {"status": "completed"},
                        "timestamp": "now"
                    }
                    break
                    
        except Exception as e:
            yield {
                "version": "v1",
                "event_type": "error",
                "data": {"error": str(e)},
                "timestamp": "now"
            }
    
    async def execute_v2_research(
        self, 
        query: str, 
        mode: str
    ) -> Iterator[Dict[str, Any]]:
        """æ‰§è¡ŒV2ç ”ç©¶æµç¨‹"""
        
        print(f"ğŸš€ å¯åŠ¨V2ç ”ç©¶æµç¨‹ï¼š{query} (æ¨¡å¼ï¼š{mode})")
        
        graph = self.get_v2_graph()
        initial_state = self.create_v2_initial_state(query, mode)
        
        config = RunnableConfig(
            configurable={
                "thread_id": "v2-research",
            }
        )
        
        try:
            print(f"ğŸ”„ å¼€å§‹æ‰§è¡ŒV2å›¾...")
            # å¤„ç†V2å›¾äº‹ä»¶ - ä½¿ç”¨å¼‚æ­¥æ–¹å¼
            async for event in graph.astream(initial_state, config={"configurable": {"thread_id": "v2-research"}}):
                print(f"ğŸ”„ V2å›¾äº‹ä»¶: {list(event.keys())}")
                
                # å‘é€çŠ¶æ€æ›´æ–°äº‹ä»¶
                yield {
                    "version": "v2",
                    "event_type": "state_update",
                    "data": event,
                    "timestamp": "now"
                }
                
                for node_name, node_data in event.items():
                    print(f"ğŸ”„ å¤„ç†èŠ‚ç‚¹: {node_name}")
                    print(f"ğŸ”„ èŠ‚ç‚¹æ•°æ®ç±»å‹: {type(node_data)}")
                    
                    if node_data is not None:
                        if isinstance(node_data, dict):
                            print(f"ğŸ”„ èŠ‚ç‚¹æ•°æ®åŒ…å«å­—æ®µ: {list(node_data.keys())}")
                            if "research_plan" in node_data:
                                print(f"ğŸ”„ ç ”ç©¶è®¡åˆ’åŒ…å« {len(node_data['research_plan'])} ä¸ªä»»åŠ¡")
                            if "is_complete" in node_data:
                                print(f"ğŸ”„ å®ŒæˆçŠ¶æ€: {node_data['is_complete']}")
                        else:
                            print(f"ğŸ”„ èŠ‚ç‚¹æ•°æ®: {str(node_data)[:100]}...")
                    
                    # ç‰¹åˆ«å…³æ³¨reflectionèŠ‚ç‚¹åçš„è·¯ç”±
                    if node_name == "reflection":
                        print(f"ğŸ”€ğŸ”€ğŸ”€ REFLECTIONèŠ‚ç‚¹å®Œæˆï¼Œç­‰å¾…ä¸‹ä¸€ä¸ªèŠ‚ç‚¹...")
                        if isinstance(node_data, dict) and node_data.get("is_complete", False):
                            print(f"ğŸ”€ğŸ”€ğŸ”€ åæ€è¿”å›is_complete=Trueï¼Œåº”è¯¥è·¯ç”±åˆ°task_coordinator")
                
                # æ£€æŸ¥å®ŒæˆçŠ¶æ€ - åªæœ‰finalize_answerèŠ‚ç‚¹å®Œæˆæ—¶æ‰çœŸæ­£ç»“æŸ
                should_complete = False
                for node_name, state in event.items():
                    if isinstance(state, dict) and state.get("is_complete", False):
                        # åªæœ‰æœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹å®Œæˆæ—¶æ‰çœŸæ­£ç»“æŸ
                        if node_name == "finalize_answer":
                            should_complete = True
                            break
                        # ä»»åŠ¡åè°ƒå™¨å’Œåæ€èŠ‚ç‚¹è¿”å›å®Œæˆæ—¶ï¼Œç»§ç»­ç­‰å¾…åç»­èŠ‚ç‚¹
                        elif node_name in ["task_coordinator", "reflection"]:
                            print(f"ğŸ”€ {node_name}èŠ‚ç‚¹å®Œæˆï¼Œä½†ç»§ç»­ç­‰å¾…åç»­èŠ‚ç‚¹å¤„ç†...")
                            continue
                
                if should_complete:
                    print(f"ğŸ”„ V2ç ”ç©¶å®Œæˆ")
                    # è·å–æœ€ç»ˆæŠ¥å‘Š
                    final_report = ""
                    completed_tasks = 0
                    for node_name, state in event.items():
                        if isinstance(state, dict):
                            if state.get("final_report_markdown"):
                                final_report = state["final_report_markdown"]
                            if state.get("report"):
                                final_report = state["report"]
                            if state.get("execution_summary"):
                                completed_tasks = state["execution_summary"].get("completed_tasks", 0)
                    
                    print(f"ğŸ“ æŠ¥å‘Šé•¿åº¦: {len(final_report or '')}")
                    yield {
                        "version": "v2",
                        "event_type": "completion",
                        "data": {
                            "status": "completed",
                            "report": final_report,
                            "completed_tasks": completed_tasks
                        },
                        "timestamp": "now"
                    }
                    break
                    
        except Exception as e:
            print(f"âŒ V2ç ”ç©¶æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            yield {
                "version": "v2",
                "event_type": "error",
                "data": {"error": str(e)},
                "timestamp": "now"
            }
    
    async def execute_research(
        self, 
        request: UnifiedResearchRequest
    ) -> Iterator[Dict[str, Any]]:
        """æ‰§è¡Œç»Ÿä¸€ç ”ç©¶æµç¨‹"""
        
        if request.version == "v1":
            async for event in self.execute_v1_research(
                request.query, 
                request.scenario_type
            ):
                yield event
        elif request.version == "v2":
            async for event in self.execute_v2_research(
                request.query, 
                request.mode
            ):
                yield event
        else:
            raise HTTPException(
                status_code=400, 
                detail=f"ä¸æ”¯æŒçš„ç‰ˆæœ¬ï¼š{request.version}"
            )


# å…¨å±€APIç®¡ç†å™¨
api_manager = APIManager()


async def stream_research_response(request: UnifiedResearchRequest):
    """æµå¼ç ”ç©¶å“åº”"""
    
    try:
        async for event in api_manager.execute_research(request):
            # æ ¹æ®ç‰ˆæœ¬å¤„ç†ä¸åŒçš„äº‹ä»¶æ ¼å¼
            if request.version == "v1":
                # V1äº‹ä»¶è½¬æ¢ä¸ºå‰ç«¯æœŸæœ›çš„æ ¼å¼
                await handle_v1_event(event, request)
                for sse_data in convert_v1_event_to_sse(event):
                    yield sse_data
            elif request.version == "v2":
                # V2äº‹ä»¶è½¬æ¢ä¸ºå‰ç«¯æœŸæœ›çš„æ ¼å¼
                for sse_data in convert_v2_event_to_sse(event):
                    yield sse_data
            
            # å°å»¶è¿Ÿä»¥ç¡®ä¿æµå¼ä½“éªŒ
            await asyncio.sleep(0.1)
            
    except Exception as e:
        if request.version == "v1":
            error_data = {"step": "error", "details": str(e)}
        else:
            error_data = {"step": "error", "details": str(e)}
        
        error_json = json.dumps(error_data, ensure_ascii=False)
        yield f"data: {error_json}\n\n"


async def handle_v1_event(event: Dict[str, Any], request: UnifiedResearchRequest):
    """å¤„ç†V1äº‹ä»¶"""
    # è¿™é‡Œå¯ä»¥æ·»åŠ V1ç‰¹å®šçš„å¤„ç†é€»è¾‘
    pass


def convert_v1_event_to_sse(event: Dict[str, Any]) -> list:
    """å°†V1äº‹ä»¶è½¬æ¢ä¸ºSSEæ ¼å¼"""
    results = []
    
    if event.get("event_type") == "completion":
        # å®Œæˆäº‹ä»¶
        complete_data = {"step": "complete", "report": ""}
        results.append(f"data: {json.dumps(complete_data, ensure_ascii=False)}\n\n")
    elif event.get("event_type") == "error":
        # é”™è¯¯äº‹ä»¶
        error_data = {"step": "error", "details": event.get("data", {}).get("error", "æœªçŸ¥é”™è¯¯")}
        results.append(f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n")
    elif event.get("event_type") == "state_update":
        # çŠ¶æ€æ›´æ–°äº‹ä»¶
        data = event.get("data", {})
        for node_name, node_data in data.items():
            if isinstance(node_data, dict):
                # æ˜ å°„èŠ‚ç‚¹åç§°åˆ°æ­¥éª¤åç§°
                step_mapping = {
                    "generate_queries_node": "generate_queries",
                    "web_search_node": "search", 
                    "reflect_node": "reflection",
                    "generate_report_node": "generate_report"
                }
                
                step_name = step_mapping.get(node_name, node_name)
                cycle = node_data.get("cycle_count", 1)
                
                # æ„å»ºæ­¥éª¤æ•°æ®
                step_data = {
                    "step": step_name,
                    "details": f"æ‰§è¡Œ{step_name}æ­¥éª¤",
                    "state": {
                        "cycle_count": cycle,
                        "search_queries": node_data.get("search_queries", []),
                        "critique": node_data.get("critique", ""),
                        "report": node_data.get("report", ""),
                        "search_results_count": len(node_data.get("search_results", []))
                    }
                }
                
                # å¦‚æœæ˜¯å®ŒæˆçŠ¶æ€æˆ–æœ‰æŠ¥å‘Šå†…å®¹
                if node_data.get("is_complete", False) or node_data.get("report"):
                    complete_data = {
                        "step": "complete",
                        "report": node_data.get("report", ""),
                        "total_cycles": cycle
                    }
                    results.append(f"data: {json.dumps(complete_data, ensure_ascii=False)}\n\n")
                else:
                    results.append(f"data: {json.dumps(step_data, ensure_ascii=False)}\n\n")
    
    return results


def convert_v2_event_to_sse(event: Dict[str, Any]) -> list:
    """å°†V2äº‹ä»¶è½¬æ¢ä¸ºSSEæ ¼å¼"""
    results = []
    
    if event.get("event_type") == "completion":
        # å®Œæˆäº‹ä»¶
        event_data = event.get("data", {})
        complete_data = {
            "step": "complete", 
            "report": event_data.get("report", ""),
            "completed_tasks": event_data.get("completed_tasks", 0),
            "data": event_data  # åŒ…å«å®Œæ•´æ•°æ®ä»¥ä¾¿å‰ç«¯è®¿é—®
        }
        results.append(f"data: {json.dumps(complete_data, ensure_ascii=False)}\n\n")
    elif event.get("event_type") == "error":
        # é”™è¯¯äº‹ä»¶
        error_data = {"step": "error", "details": event.get("data", {}).get("error", "æœªçŸ¥é”™è¯¯")}
        results.append(f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n")
    elif event.get("event_type") == "state_update":
        # V2çŠ¶æ€æ›´æ–°äº‹ä»¶
        data = event.get("data", {})
        for node_name, node_data in data.items():
            if isinstance(node_data, dict):
                # ç”ŸæˆV2èŠ‚ç‚¹çš„å‹å¥½æ­¥éª¤ä¿¡æ¯
                step_info = generate_v2_step_info(node_name, node_data)
                if step_info:
                    results.append(f"data: {json.dumps(step_info, ensure_ascii=False)}\n\n")
    
    return results


def generate_v2_step_info(node_name: str, node_data: dict) -> dict:
    """ç”ŸæˆV2èŠ‚ç‚¹çš„å‹å¥½æ­¥éª¤ä¿¡æ¯"""
    
    # è·å–å½“å‰ä»»åŠ¡ä¿¡æ¯
    current_task = None
    current_task_name = "æœªçŸ¥ä»»åŠ¡"
    cycle = 1
    
    if "research_plan" in node_data and "current_task_pointer" in node_data:
        research_plan = node_data["research_plan"]
        pointer = node_data.get("current_task_pointer", 0)
        if 0 <= pointer < len(research_plan):
            current_task = research_plan[pointer]
            if hasattr(current_task, 'description'):
                current_task_name = current_task.description
            elif isinstance(current_task, dict):
                current_task_name = current_task.get('description', 'æœªçŸ¥ä»»åŠ¡')
    
    # è·å–å¾ªç¯æ¬¡æ•°
    cycle = node_data.get("current_task_loop_count", 1) or 1
    
    # æ ¹æ®èŠ‚ç‚¹ç±»å‹ç”Ÿæˆå‹å¥½çš„æ­¥éª¤ä¿¡æ¯
    if node_name == "planner":
        return {
            "step": "planning",
            "details": "ğŸ§  æ™ºèƒ½è§„åˆ’ - åˆ†ææŸ¥è¯¢å¤æ‚åº¦å¹¶ç”Ÿæˆç ”ç©¶è®¡åˆ’",
            "state": {
                "tasks": [
                    {
                        "id": getattr(task, 'id', f'task-{i}') if hasattr(task, 'id') else (task.get('id', f'task-{i}') if isinstance(task, dict) else f'task-{i}'),
                        "name": getattr(task, 'description', f'ä»»åŠ¡{i+1}') if hasattr(task, 'description') else (task.get('description', f'ä»»åŠ¡{i+1}') if isinstance(task, dict) else f'ä»»åŠ¡{i+1}'),
                        "type": "research",
                        "priority": i + 1,
                        "status": "pending",
                        "cycles_completed": 0,
                        "max_cycles": 3
                    }
                    for i, task in enumerate(node_data.get("research_plan", []))
                ],
                "complexity_score": node_data.get("total_estimated_cycles", 0) / 3 if node_data.get("total_estimated_cycles") else None,
                "total_tasks": len(node_data.get("research_plan", [])),
                "completed_tasks": 0
            }
        }
    
    elif node_name == "task_coordinator":
        completed_tasks = len(node_data.get("completed_tasks", []))
        total_tasks = len(node_data.get("research_plan", []))
        
        return {
            "step": "task_coordination",
            "details": f"ğŸ¯ ä»»åŠ¡åè°ƒ - ç®¡ç†ç ”ç©¶è¿›åº¦ ({completed_tasks}/{total_tasks} ä»»åŠ¡å®Œæˆ)",
            "state": {
                "current_task": {
                    "id": getattr(current_task, 'id', 'unknown') if current_task and hasattr(current_task, 'id') else (current_task.get('id', 'unknown') if current_task and isinstance(current_task, dict) else 'unknown'),
                    "name": current_task_name,
                    "cycles_completed": cycle
                } if current_task else None,
                "completed_tasks": completed_tasks,
                "total_tasks": total_tasks
            }
        }
    
    elif node_name == "generate_query":
        return {
            "step": "query_generation",
            "details": f"ğŸ” [{current_task_name}] ç¬¬{cycle}è½® - ç”Ÿæˆæœç´¢æŸ¥è¯¢",
            "state": {
                "current_task": {
                    "name": current_task_name,
                    "cycles_completed": cycle
                },
                "search_queries": node_data.get("search_queries", [])
            }
        }
    
    elif node_name == "web_research":
        search_results_count = len(node_data.get("search_results", []))
        return {
            "step": "web_search",
            "details": f"ğŸŒ [{current_task_name}] ç¬¬{cycle}è½® - æ‰§è¡Œç½‘ç»œæœç´¢ (è·å¾—{search_results_count}æ¡ç»“æœ)",
            "state": {
                "current_task": {
                    "name": current_task_name,
                    "cycles_completed": cycle
                },
                "search_results_count": search_results_count
            }
        }
    
    elif node_name == "reflection":
        is_complete = node_data.get("is_complete", False)
        critique = node_data.get("critique", "")
        
        return {
            "step": "reflection",
            "details": f"ğŸ¤” [{current_task_name}] ç¬¬{cycle}è½® - åæ€å’Œåˆ†æ ({'å®Œæˆ' if is_complete else 'ç»§ç»­'})",
            "state": {
                "current_task": {
                    "name": current_task_name,
                    "cycles_completed": cycle
                },
                "critique": critique[:100] + "..." if len(critique) > 100 else critique,
                "is_complete": is_complete
            }
        }
    
    elif node_name == "finalize_answer":
        report_length = len(node_data.get("report", "") or node_data.get("final_report_markdown", ""))
        return {
            "step": "report_generation",
            "details": f"ğŸ“„ ç”Ÿæˆç»¼åˆæŠ¥å‘Š (æŠ¥å‘Šé•¿åº¦: {report_length} å­—ç¬¦)",
            "state": {
                "report_length": report_length,
                "is_complete": True
            }
        }
    
    # é»˜è®¤æƒ…å†µ
    return {
        "step": node_name,
        "details": f"æ‰§è¡ŒèŠ‚ç‚¹: {node_name}",
        "state": {}
    }


def create_unified_research_endpoint(app: FastAPI):
    """åˆ›å»ºç»Ÿä¸€ç ”ç©¶ç«¯ç‚¹"""
    
    @app.post("/unified-research")
    async def unified_research(request: UnifiedResearchRequest):
        """
        ç»Ÿä¸€ç ”ç©¶ç«¯ç‚¹
        æ”¯æŒV1å’ŒV2ä¸¤ç§æ¶æ„
        """
        
        print(f"ğŸ“¡ æ”¶åˆ°ç»Ÿä¸€ç ”ç©¶è¯·æ±‚ï¼š")
        print(f"  æŸ¥è¯¢ï¼š{request.query}")
        print(f"  ç‰ˆæœ¬ï¼š{request.version}")
        print(f"  åœºæ™¯/æ¨¡å¼ï¼š{request.scenario_type if request.version == 'v1' else request.mode}")
        
        return StreamingResponse(
            stream_research_response(request),
            media_type="text/plain; charset=utf-8",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
                "Access-Control-Allow-Headers": "Content-Type",
            }
        )
    
    @app.get("/research-versions")
    async def get_research_versions():
        """è·å–æ”¯æŒçš„ç ”ç©¶ç‰ˆæœ¬"""
        return {
            "versions": [
                {
                    "version": "v1",
                    "name": "ç»å…¸ç ”ç©¶æ¶æ„",
                    "description": "åŸºç¡€çš„å¤šè½®æœç´¢å’ŒæŠ¥å‘Šç”Ÿæˆ",
                    "scenarios": ["simple", "adaptive", "complex"]
                },
                {
                    "version": "v2", 
                    "name": "é«˜çº§æ™ºèƒ½æ¶æ„",
                    "description": "æ™ºèƒ½è§„åˆ’ã€å¤šä»»åŠ¡åè°ƒã€å†…å®¹å¢å¼º",
                    "modes": ["research_assistant", "quick_lookup", "deep_research"]
                }
            ]
        }
    
    print("ğŸ”— ç»Ÿä¸€ç ”ç©¶ç«¯ç‚¹å·²åˆ›å»º")


def get_api_manager() -> APIManager:
    """è·å–APIç®¡ç†å™¨å®ä¾‹"""
    return api_manager 