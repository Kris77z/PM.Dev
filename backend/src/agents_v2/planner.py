"""
æ™ºèƒ½è§„åˆ’å™¨èŠ‚ç‚¹
åŸºäº langgraph-deep-research é¡¹ç›®çš„è§„åˆ’æ¶æ„
å°†å¤æ‚ç”¨æˆ·æŸ¥è¯¢åˆ†è§£ä¸ºå¤šä¸ªå¯æ‰§è¡Œçš„ç ”ç©¶ä»»åŠ¡
"""

import os
from typing import Dict, List, Any
from dataclasses import dataclass
from langchain_core.runnables import RunnableConfig
from pydantic import BaseModel, Field
from langchain_google_genai import ChatGoogleGenerativeAI

from .advanced_state import AdvancedResearchState, ResearchTask, PlanningState


@dataclass
class QueryComplexityAnalysis:
    """æŸ¥è¯¢å¤æ‚åº¦åˆ†æç»“æœ"""
    complexity_score: float  # 0-1ï¼Œå¤æ‚åº¦è¯„åˆ†
    domain_count: int        # æ¶‰åŠé¢†åŸŸæ•°é‡
    temporal_scope: str      # æ—¶é—´èŒƒå›´ï¼šcurrent/historical/future
    technical_depth: str     # æŠ€æœ¯æ·±åº¦ï¼šbasic/intermediate/advanced
    recommended_tasks: int   # æ¨èä»»åŠ¡æ•°é‡
    estimated_cycles: int    # é¢„ä¼°æ€»è½®æ¬¡


class ResearchPlanSchema(BaseModel):
    """ç ”ç©¶è®¡åˆ’è¾“å‡ºæ¶æ„"""
    tasks: List[Dict[str, Any]] = Field(
        description="ç ”ç©¶ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡åŒ…å«idã€descriptionã€source_hintç­‰å­—æ®µ"
    )


class PlannerAgent:
    """æ™ºèƒ½è§„åˆ’ä»£ç†"""
    
    def __init__(self):
        self.llm = None
        
    def get_llm(self, config: RunnableConfig = None) -> ChatGoogleGenerativeAI:
        """è·å–LLMå®ä¾‹"""
        if not self.llm:
            api_key = os.getenv("GOOGLE_API_KEY")  # ä¸V1ä¿æŒä¸€è‡´
            if not api_key:
                raise ValueError("GOOGLE_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®")
            
            try:
                self.llm = ChatGoogleGenerativeAI(
                    model="gemini-1.5-flash",
                    temperature=0.3,  # è§„åˆ’éœ€è¦è¾ƒä½æ¸©åº¦ä¿è¯é€»è¾‘æ€§
                    max_retries=2,
                    api_key=api_key,  # ä½¿ç”¨æ ‡å‡†å‚æ•°å
                )
                print(f"âœ… V2 LLMå®ä¾‹åˆ›å»ºæˆåŠŸ")
            except Exception as e:
                print(f"âŒ V2 LLMå®ä¾‹åˆ›å»ºå¤±è´¥ï¼š{e}")
                raise
        return self.llm

    def analyze_query_complexity(self, user_query: str) -> QueryComplexityAnalysis:
        """åˆ†ææŸ¥è¯¢å¤æ‚åº¦"""
        
        # ç®€å•çš„å¤æ‚åº¦åˆ†æè§„åˆ™
        query_lower = user_query.lower()
        
        # è®¡ç®—é¢†åŸŸæ•°é‡ï¼ˆåŸºäºå…³é”®è¯ï¼‰
        domains = {
            "tech": ["ai", "äººå·¥æ™ºèƒ½", "machine learning", "åŒºå—é“¾", "blockchain", "é‡å­è®¡ç®—", "quantum"],
            "business": ["å¸‚åœº", "market", "å•†ä¸š", "business", "ç®¡ç†", "management", "é‡‘è", "finance"],
            "health": ["åŒ»ç–—", "health", "healthcare", "åŒ»å­¦", "medicine", "å¥åº·"],
            "education": ["æ•™è‚²", "education", "å­¦ä¹ ", "learning", "åŸ¹è®­", "training"],
            "environment": ["ç¯å¢ƒ", "environment", "ç»¿è‰²", "green", "å¯æŒç»­", "sustainable"],
            "social": ["ç¤¾ä¼š", "social", "æ–‡åŒ–", "culture", "æ”¿ç­–", "policy"]
        }
        
        domain_count = 0
        for domain, keywords in domains.items():
            if any(keyword in query_lower for keyword in keywords):
                domain_count += 1
        
        # åˆ†ææ—¶é—´èŒƒå›´
        temporal_indicators = {
            "current": ["2024", "ç°åœ¨", "å½“å‰", "ç›®å‰", "current", "now", "today"],
            "future": ["æœªæ¥", "å‰æ™¯", "è¶‹åŠ¿", "future", "trend", "projection", "forecast"],
            "historical": ["å†å²", "è¿‡å»", "å‘å±•", "history", "past", "evolution"]
        }
        
        temporal_scope = "current"  # é»˜è®¤
        for scope, indicators in temporal_indicators.items():
            if any(indicator in query_lower for indicator in indicators):
                temporal_scope = scope
                break
        
        # åˆ†ææŠ€æœ¯æ·±åº¦
        technical_indicators = {
            "advanced": ["æŠ€æœ¯æŒ‘æˆ˜", "å®ç°", "implementation", "technical", "æ¶æ„", "algorithm"],
            "intermediate": ["åº”ç”¨", "application", "ä½¿ç”¨", "æ–¹æ³•", "method"],
            "basic": ["ä»‹ç»", "æ¦‚è¿°", "overview", "åŸºç¡€", "basic"]
        }
        
        technical_depth = "intermediate"  # é»˜è®¤
        for depth, indicators in technical_indicators.items():
            if any(indicator in query_lower for indicator in indicators):
                technical_depth = depth
                break
        
        # è®¡ç®—å¤æ‚åº¦è¯„åˆ†
        complexity_score = min(1.0, (
            len(query_lower.split()) / 20 * 0.3 +  # æŸ¥è¯¢é•¿åº¦
            domain_count / 3 * 0.4 +               # é¢†åŸŸæ•°é‡
            {"basic": 0.2, "intermediate": 0.5, "advanced": 0.8}[technical_depth] * 0.3
        ))
        
        # æ¨èä»»åŠ¡æ•°é‡
        if complexity_score < 0.3:
            recommended_tasks = 2
        elif complexity_score < 0.6:
            recommended_tasks = 3
        elif complexity_score < 0.8:
            recommended_tasks = 4
        else:
            recommended_tasks = 5
            
        # é¢„ä¼°è½®æ¬¡
        estimated_cycles = recommended_tasks * 2 + domain_count
        
        return QueryComplexityAnalysis(
            complexity_score=complexity_score,
            domain_count=max(1, domain_count),
            temporal_scope=temporal_scope,
            technical_depth=technical_depth,
            recommended_tasks=recommended_tasks,
            estimated_cycles=estimated_cycles
        )

    def generate_planning_prompt(self, user_query: str, complexity: QueryComplexityAnalysis) -> str:
        """ç”Ÿæˆè§„åˆ’æç¤ºè¯"""
        
        return f"""ä½ æ˜¯ **PlannerAgent**ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·ç ”ç©¶æŸ¥è¯¢å¹¶å°†å…¶åˆ†è§£ä¸ºå¤šä¸ªå…·ä½“ã€å¯æ‰§è¡Œçš„ç ”ç©¶ä»»åŠ¡ã€‚

=== ä»»åŠ¡åˆ†æåŸåˆ™ ===
1. **åˆ†è§£å¤æ‚æŸ¥è¯¢**ï¼šå°†å¹¿æ³›ä¸»é¢˜åˆ†è§£ä¸ºå…·ä½“ã€å¯ç®¡ç†çš„å­ä»»åŠ¡
2. **è¯†åˆ«å…³é”®ç»´åº¦**ï¼šæå–ä¸åŒæ–¹é¢ã€ç±»åˆ«æˆ–é¢†åŸŸ
3. **åˆ›å»ºå¹¶è¡Œä»»åŠ¡**ï¼šç”Ÿæˆ2-5ä¸ªå¯ç‹¬ç«‹ç ”ç©¶çš„èšç„¦ä»»åŠ¡
4. **ç¡®ä¿å…¨é¢è¦†ç›–**ï¼šæ‰€æœ‰é‡è¦æ–¹é¢éƒ½åº”è¢«æ¶µç›–

=== å½“å‰æŸ¥è¯¢åˆ†æ ===
- å¤æ‚åº¦è¯„åˆ†ï¼š{complexity.complexity_score:.2f}
- æ¶‰åŠé¢†åŸŸæ•°ï¼š{complexity.domain_count}
- æ—¶é—´èŒƒå›´ï¼š{complexity.temporal_scope}
- æŠ€æœ¯æ·±åº¦ï¼š{complexity.technical_depth}
- æ¨èä»»åŠ¡æ•°ï¼š{complexity.recommended_tasks}

=== ä»»åŠ¡åˆ†è§£ç­–ç•¥ ===
åŸºäºç ”ç©¶æŸ¥è¯¢ï¼Œè€ƒè™‘è¿™äº›ç»´åº¦ï¼š
- **é¢†åŸŸåˆ†ç¦»**ï¼šåˆ†å‰²ä¸åŒå­—æ®µ/è¡Œä¸šï¼ˆå¦‚äº¤é€š vs èƒ½æºï¼‰
- **åœ°ç†èŒƒå›´**ï¼šä¸åŒåœ°åŒºæˆ–å…¨çƒ vs æœ¬åœ°
- **æ—¶é—´ç„¦ç‚¹**ï¼šå½“å‰è¶‹åŠ¿ vs æœªæ¥é¢„æµ‹ vs å†å²åˆ†æ
- **æŠ€æœ¯æ·±åº¦**ï¼šæ¦‚è¿° vs å®ç°ç»†èŠ‚ vs æ¡ˆä¾‹ç ”ç©¶
- **åˆ©ç›Šç›¸å…³è€…è§†è§’**ï¼šæ”¿åºœã€è¡Œä¸šã€æŠ€æœ¯ã€ç”¨æˆ·å½±å“

=== è¾“å‡ºæ ¼å¼ ===
è¿”å›ä¸€ä¸ªJSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ å¿…é¡»åŒ…å«ä»¥ä¸‹å­—æ®µï¼š

{{
  "id": "<kebab-case-unique-slug>",
  "description": "<ä¸€ä¸ªå…·ä½“ã€èšç„¦çš„ç ”ç©¶ä»»åŠ¡>", 
  "info_needed": true,
  "source_hint": "<æ­¤ä»»åŠ¡çš„å…·ä½“æœç´¢å…³é”®è¯>",
  "status": "pending",
  "priority": 1-5,
  "task_type": "general|technical|comparison|analysis",
  "estimated_cycles": 2-4
}}

=== è§„åˆ’ç¤ºä¾‹ ===

**ç¤ºä¾‹1**ï¼šç”¨æˆ·æŸ¥è¯¢ï¼š"äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨ç°çŠ¶"
[
  {{
    "id": "ai-medical-diagnostics",
    "description": "ç ”ç©¶AIåœ¨åŒ»ç–—è¯Šæ–­å’Œå½±åƒå­¦ä¸­çš„åº”ç”¨",
    "info_needed": true,
    "source_hint": "AIåŒ»ç–—è¯Šæ–­ å½±åƒå­¦ æœºå™¨å­¦ä¹  åŒ»ç–—å¥åº· 2024",
    "status": "pending",
    "priority": 1,
    "task_type": "technical", 
    "estimated_cycles": 3
  }},
  {{
    "id": "ai-treatment-recommendations",
    "description": "ç ”ç©¶AIé©±åŠ¨çš„æ²»ç–—å»ºè®®å’Œè¯ç‰©å‘ç°",
    "info_needed": true,
    "source_hint": "AIæ²»ç–—å»ºè®® è¯ç‰©å‘ç° ä¸ªæ€§åŒ–åŒ»ç–—",
    "status": "pending",
    "priority": 2,
    "task_type": "analysis",
    "estimated_cycles": 3
  }},
  {{
    "id": "ai-healthcare-challenges",
    "description": "åˆ†æAIåœ¨åŒ»ç–—é¢†åŸŸçš„æŒ‘æˆ˜å’Œä¼¦ç†è€ƒé‡",
    "info_needed": true,
    "source_hint": "AIåŒ»ç–—ä¼¦ç† éšç§æŒ‘æˆ˜ ç›‘ç®¡é—®é¢˜",
    "status": "pending", 
    "priority": 3,
    "task_type": "analysis",
    "estimated_cycles": 2
  }}
]

=== è¦æ±‚ ===
1. **å§‹ç»ˆåˆ›å»º{complexity.recommended_tasks}ä¸ªä»»åŠ¡**ï¼ˆé™¤éæŸ¥è¯¢æå…¶å…·ä½“ï¼‰
2. **æ¯ä¸ªä»»åŠ¡åº”èšç„¦ä¸”å…·ä½“**
3. **ä»»åŠ¡åº”äº’è¡¥ä½†ç‹¬ç«‹**
4. **ä½¿ç”¨æè¿°æ€§ã€å¯æ“ä½œçš„ä»»åŠ¡æè¿°**
5. **ä¸ºæ¯ä¸ªä»»åŠ¡æä¾›é’ˆå¯¹æ€§çš„æœç´¢æç¤º**
6. **è€ƒè™‘ä¼˜å…ˆçº§å’Œé¢„ä¼°è½®æ¬¡**

=== å½“å‰ç ”ç©¶æŸ¥è¯¢ ===
ç”¨æˆ·æŸ¥è¯¢ï¼š{user_query}

=== æŒ‡ä»¤ ===
åˆ†æç”¨æˆ·æŸ¥è¯¢å¹¶å°†å…¶åˆ†è§£ä¸ºå…·ä½“çš„ç ”ç©¶ä»»åŠ¡ã€‚ä¸“æ³¨äºåˆ›å»ºå¤šä¸ªèšç„¦ä»»åŠ¡è€Œä¸æ˜¯ä¸€ä¸ªå¹¿æ³›ä»»åŠ¡ã€‚**åª**è¾“å‡ºJSONæ•°ç»„ã€‚"""

    def create_research_plan(self, user_query: str, config: RunnableConfig = None) -> List[ResearchTask]:
        """åˆ›å»ºç ”ç©¶è®¡åˆ’"""
        
        print(f"ğŸ“ å¼€å§‹åˆ›å»ºç ”ç©¶è®¡åˆ’...")
        print(f"ğŸ“ ç”¨æˆ·æŸ¥è¯¢: {user_query}")
        
        # åˆ†ææŸ¥è¯¢å¤æ‚åº¦
        print(f"ğŸ“ åˆ†ææŸ¥è¯¢å¤æ‚åº¦...")
        complexity = self.analyze_query_complexity(user_query)
        print(f"ğŸ“ å¤æ‚åº¦åˆ†æå®Œæˆ: è¯„åˆ†={complexity.complexity_score:.2f}, æ¨èä»»åŠ¡æ•°={complexity.recommended_tasks}")
        
        # ç”Ÿæˆè§„åˆ’æç¤º
        print(f"ğŸ“ ç”Ÿæˆè§„åˆ’æç¤º...")
        prompt = self.generate_planning_prompt(user_query, complexity)
        print(f"ğŸ“ æç¤ºé•¿åº¦: {len(prompt)} å­—ç¬¦")
        
        try:
            # ä½¿ç”¨ä¸V1ç›¸åŒçš„ç›´æ¥APIè°ƒç”¨æ–¹å¼
            print(f"ğŸ“ ä½¿ç”¨ç›´æ¥APIè°ƒç”¨...")
            response_text = self.invoke_gemini_api_direct(prompt)
            print(f"ğŸ“ APIè°ƒç”¨æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
            print(f"ğŸ“ å“åº”å†…å®¹å‰100å­—ç¬¦: {response_text[:100]}...")
            
            # æ‰‹åŠ¨è§£æJSON
            print(f"ğŸ“ è§£æJSONå“åº”...")
            import json
            
            # æ¸…ç†å“åº”æ–‡æœ¬ï¼Œæå–JSONéƒ¨åˆ†
            response_text = response_text.strip()
            if response_text.startswith('```json'):
                response_text = response_text[7:]
            if response_text.endswith('```'):
                response_text = response_text[:-3]
            if response_text.startswith('['):
                # ç›´æ¥æ˜¯JSONæ•°ç»„
                tasks_data = json.loads(response_text)
            else:
                # å¯èƒ½åŒ…å«å…¶ä»–æ–‡æœ¬ï¼Œå°è¯•æ‰¾åˆ°JSONéƒ¨åˆ†
                import re
                json_match = re.search(r'\[.*\]', response_text, re.DOTALL)
                if json_match:
                    tasks_data = json.loads(json_match.group())
                else:
                    raise ValueError("æ— æ³•åœ¨å“åº”ä¸­æ‰¾åˆ°JSONæ•°ç»„")
            
            print(f"ğŸ“ è§£ææˆåŠŸï¼Œè·å¾— {len(tasks_data)} ä¸ªä»»åŠ¡")
            
            # è½¬æ¢ä¸ºResearchTaskå¯¹è±¡
            print(f"ğŸ“ è½¬æ¢ä¸ºResearchTaskå¯¹è±¡...")
            research_tasks = []
            for i, task_data in enumerate(tasks_data):
                print(f"ğŸ“ å¤„ç†ä»»åŠ¡ {i+1}: {task_data.get('id', 'unknown')}")
                task = ResearchTask(
                    id=task_data.get("id", f"task-{i+1}"),
                    description=task_data.get("description", f"ç ”ç©¶ä»»åŠ¡ {i+1}"),
                    priority=task_data.get("priority", 1),
                    status=task_data.get("status", "pending"),
                    task_type=task_data.get("task_type", "general"),
                    estimated_cycles=task_data.get("estimated_cycles", 2),
                    info_needed=task_data.get("info_needed", True),
                    source_hint=task_data.get("source_hint", task_data.get("description", ""))
                )
                research_tasks.append(task)
            
            print(f"ğŸ¯ æˆåŠŸç”Ÿæˆç ”ç©¶è®¡åˆ’ï¼š{len(research_tasks)}ä¸ªä»»åŠ¡")
            for task in research_tasks:
                print(f"  - {task.id}: {task.description}")
            
            return research_tasks
            
        except Exception as e:
            print(f"âŒ è§„åˆ’ç”Ÿæˆå¤±è´¥ï¼š{e}")
            import traceback
            traceback.print_exc()
            
            # fallbackï¼šåˆ›å»ºå•ä¸€ä»»åŠ¡
            print(f"ğŸ“ ä½¿ç”¨fallbackä»»åŠ¡...")
            fallback_task = ResearchTask(
                id="task-1",
                description=f"ç ”ç©¶å’Œå›ç­”ï¼š{user_query}",
                priority=1,
                status="pending",
                task_type="general",
                estimated_cycles=3,
                info_needed=True,
                source_hint=user_query
            )
            
            return [fallback_task]
    
    def invoke_gemini_api_direct(self, prompt: str) -> str:
        """
        ç›´æ¥è°ƒç”¨Gemini APIï¼Œä½¿ç”¨ä¸V1ç›¸åŒçš„æ–¹æ³•
        """
        import httpx
        import os
        
        api_key = os.getenv("GOOGLE_API_KEY")
        proxy_url = os.getenv("HTTPS_PROXY")
        
        # åªåœ¨å¼€å‘ç¯å¢ƒæˆ–æ˜ç¡®é…ç½®æ—¶ä½¿ç”¨ä»£ç†
        # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå¦‚æœä»£ç†URLæ˜¯localhostï¼Œåˆ™ä¸ä½¿ç”¨ä»£ç†
        transport = None
        if proxy_url and not proxy_url.startswith(('http://127.0.0.1', 'http://localhost')):
            transport = httpx.HTTPTransport(proxy=proxy_url)
        elif proxy_url:
            print(f"è·³è¿‡æœ¬åœ°ä»£ç†é…ç½®: {proxy_url} (ç”Ÿäº§ç¯å¢ƒä¸ä½¿ç”¨)")
        
        if not api_key:
            raise ValueError("GOOGLE_API_KEY is not set.")

        request_body = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {
                "temperature": 0.3,
                "responseMimeType": "application/json"
            }
        }

        try:
            with httpx.Client(transport=transport, timeout=60.0) as client:
                response = client.post(
                    f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={api_key}",
                    json=request_body,
                )
                response.raise_for_status()
                
                response_json = response.json()
                return response_json["candidates"][0]["content"]["parts"][0]["text"]

        except httpx.RequestError as e:
            print(f"ERROR: An HTTP request error occurred: {e}")
            raise Exception(f"Error: The request to Gemini API failed. Details: {e}")
        except Exception as e:
            print(f"ERROR: A general error occurred in invoke_gemini_api_direct: {e}")
            raise Exception(f"Error: An unexpected error occurred. Details: {e}")


# å…¨å±€è§„åˆ’å™¨å®ä¾‹
_planner_agent = PlannerAgent()


def planner_node(state: AdvancedResearchState, config: RunnableConfig) -> Dict[str, Any]:
    """
    LangGraphè§„åˆ’å™¨èŠ‚ç‚¹
    å°†ç”¨æˆ·æŸ¥è¯¢è½¬æ¢ä¸ºå¤šæ­¥éª¤ç ”ç©¶è®¡åˆ’
    """
    
    try:
        # è·å–ç”¨æˆ·æŸ¥è¯¢
        user_query = state.get("user_query", "")
        if not user_query:
            # ä»æ¶ˆæ¯ä¸­æå–æŸ¥è¯¢ï¼ˆå…¼å®¹æ€§å¤„ç†ï¼‰
            messages = state.get("messages", [])
            if messages:
                user_query = str(messages[-1])
        
        if not user_query:
            raise ValueError("æ— æ³•è·å–ç”¨æˆ·æŸ¥è¯¢")
        
        print(f"ğŸ¯ å¼€å§‹è§„åˆ’ç ”ç©¶ä»»åŠ¡...")
        print(f"  ç”¨æˆ·æŸ¥è¯¢ï¼š{user_query}")
        
        # åˆ›å»ºç ”ç©¶è®¡åˆ’
        research_plan = _planner_agent.create_research_plan(user_query, config)
        
        # è®¡ç®—é¢„ä¼°æ€»è½®æ¬¡
        total_estimated_cycles = sum(task.estimated_cycles for task in research_plan)
        
        print(f"ğŸ“‹ è§„åˆ’å®Œæˆï¼š")
        print(f"  ä»»åŠ¡æ•°é‡ï¼š{len(research_plan)}")
        print(f"  é¢„ä¼°æ€»è½®æ¬¡ï¼š{total_estimated_cycles}")
        
        # å°†ResearchTaskå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œç¡®ä¿å¯åºåˆ—åŒ–
        research_plan_dicts = []
        for task in research_plan:
            task_dict = {
                "id": task.id,
                "description": task.description,
                "priority": task.priority,
                "status": task.status,
                "task_type": task.task_type,
                "estimated_cycles": task.estimated_cycles,
                "info_needed": task.info_needed,
                "source_hint": task.source_hint
            }
            research_plan_dicts.append(task_dict)
        
        # è¿”å›çŠ¶æ€æ›´æ–°
        result = {
            "user_query": user_query,
            "research_plan": research_plan_dicts,  # ä½¿ç”¨å­—å…¸æ ¼å¼
            "current_task_pointer": 0,
            "total_estimated_cycles": total_estimated_cycles,
            "completed_tasks": [],
            "failed_tasks": [],
            "reasoning_model": "gemini-1.5-flash",
            
            # å…¼å®¹æ€§å­—æ®µ
            "plan": [
                {
                    "id": task.id,
                    "description": task.description,
                    "info_needed": task.info_needed,
                    "source_hint": task.source_hint,
                    "status": task.status
                }
                for task in research_plan
            ]
        }
        
        print(f"âœ… è§„åˆ’å™¨èŠ‚ç‚¹æ‰§è¡ŒæˆåŠŸï¼Œè¿”å› {len(result)} ä¸ªå­—æ®µ")
        return result
        
    except Exception as e:
        print(f"âŒ è§„åˆ’å™¨èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥ï¼š{e}")
        import traceback
        traceback.print_exc()
        
        # è¿”å›fallbackçŠ¶æ€
        fallback_task_dict = {
            "id": "fallback-task",
            "description": f"ç ”ç©¶ï¼š{state.get('user_query', 'æœªçŸ¥æŸ¥è¯¢')}",
            "priority": 1,
            "status": "pending",
            "task_type": "general",
            "estimated_cycles": 3,
            "info_needed": True,
            "source_hint": state.get('user_query', '')
        }
        
        return {
            "user_query": state.get("user_query", ""),
            "research_plan": [fallback_task_dict],  # ä½¿ç”¨å­—å…¸æ ¼å¼
            "current_task_pointer": 0,
            "total_estimated_cycles": 3,
            "completed_tasks": [],
            "failed_tasks": [],
            "reasoning_model": "gemini-1.5-flash",
            "plan": [fallback_task_dict]
        }


def get_current_task(state: AdvancedResearchState) -> ResearchTask:
    """è·å–å½“å‰ä»»åŠ¡"""
    research_plan = state.get("research_plan", [])
    current_pointer = state.get("current_task_pointer", 0)
    
    if current_pointer < len(research_plan):
        task_data = research_plan[current_pointer]
        
        # å¦‚æœæ˜¯å­—å…¸æ ¼å¼ï¼Œè½¬æ¢ä¸ºResearchTaskå¯¹è±¡
        if isinstance(task_data, dict):
            return ResearchTask(
                id=task_data.get("id", f"task-{current_pointer}"),
                description=task_data.get("description", "æœªçŸ¥ä»»åŠ¡"),
                priority=task_data.get("priority", 1),
                status=task_data.get("status", "pending"),
                task_type=task_data.get("task_type", "general"),
                estimated_cycles=task_data.get("estimated_cycles", 2),
                info_needed=task_data.get("info_needed", True),
                source_hint=task_data.get("source_hint", "")
            )
        # å¦‚æœå·²ç»æ˜¯ResearchTaskå¯¹è±¡ï¼Œç›´æ¥è¿”å›
        elif isinstance(task_data, ResearchTask):
            return task_data
    
    # è¿”å›é»˜è®¤ä»»åŠ¡
    return ResearchTask(
        id="default-task",
        description="é»˜è®¤ç ”ç©¶ä»»åŠ¡",
        priority=1,
        status="pending"
    )


def is_planning_complete(state: AdvancedResearchState) -> bool:
    """åˆ¤æ–­è§„åˆ’æ˜¯å¦å®Œæˆ"""
    
    # é¦–å…ˆæ£€æŸ¥åæ€æ˜¯å¦å†³å®šå®Œæˆæ•´ä¸ªç ”ç©¶
    if state.get("is_complete", False):
        print(f"ğŸ åæ€å†³å®šç ”ç©¶å®Œæˆï¼Œç»“æŸæ‰€æœ‰ä»»åŠ¡")
        return True
    
    # ç„¶åæ£€æŸ¥æ˜¯å¦æ‰€æœ‰ä»»åŠ¡éƒ½å·²å®Œæˆ
    research_plan = state.get("research_plan", [])
    current_pointer = state.get("current_task_pointer", 0)
    
    all_tasks_done = current_pointer >= len(research_plan)
    if all_tasks_done:
        print(f"ğŸ æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ ({current_pointer}/{len(research_plan)})")
    
    return all_tasks_done 