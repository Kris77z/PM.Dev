"""
FastAPIä¸»åº”ç”¨
æ”¯æŒV1å’ŒV2ä¸¤ç§LangGraphæ¶æ„çš„ç ”ç©¶åŠŸèƒ½
"""

import os
import json
import asyncio
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Dict, Any, AsyncGenerator
from langchain_core.runnables import RunnableConfig
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# V1æ¶æ„å¯¼å…¥
from agent.graph import build_graph
from agent.state import ResearchState

# V2æ¶æ„å¯¼å…¥
from unified_api import create_unified_research_endpoint, UnifiedResearchRequest

# V1.5 å¿«é€Ÿæœç´¢APIå¯¼å…¥
from quick_search_api import create_quick_search_endpoints


class ResearchRequest(BaseModel):
    """V1ç ”ç©¶è¯·æ±‚ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰"""
    query: str
    scenario_type: str = "default"


# åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†
@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨å¯åŠ¨å’Œå…³é—­æ—¶çš„å¤„ç†"""
    print("ğŸš€ FastAPIåº”ç”¨å¯åŠ¨")
    print("ğŸ”§ åˆå§‹åŒ–LangGraphç ”ç©¶ç³»ç»Ÿ...")
    
    # å¯ä»¥åœ¨è¿™é‡Œè¿›è¡Œé¢„çƒ­æˆ–åˆå§‹åŒ–
    try:
        # æµ‹è¯•V1å›¾
        test_state: ResearchState = {
            "user_query": "æµ‹è¯•", 
            "search_queries": [], 
            "search_results": [], 
            "critique": "", 
            "report": "", 
            "is_complete": False, 
            "cycle_count": 0
        }
        print("âœ… V1æ¶æ„æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•V2å›¾ï¼ˆå¦‚æœéœ€è¦ï¼‰
        # test_v2_graph = get_advanced_research_graph()
        print("âœ… V2æ¶æ„å‡†å¤‡å°±ç»ª")
        
    except Exception as e:
        print(f"âš ï¸ åˆå§‹åŒ–è­¦å‘Šï¼š{e}")
    
    print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    yield
    
    print("ğŸ›‘ FastAPIåº”ç”¨å…³é—­")


# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="LangGraph Research API",
    description="æ”¯æŒå¤šç§æ¶æ„çš„æ™ºèƒ½ç ”ç©¶API",
    version="2.0.0",
    lifespan=lifespan
)

# CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ===== V1 APIï¼ˆä¿æŒç°æœ‰åŠŸèƒ½ï¼‰ =====

async def stream_research_v1(query: str, scenario_type: str) -> AsyncGenerator[str, None]:
    """
    V1ç ”ç©¶æµå¼å¤„ç† - æ”¯æŒæ–°çš„ç”¨æˆ·å‹å¥½æ ¼å¼
    """
    initial_state = {
        "user_query": query,
        "search_queries": [],
        "search_results": [],
        "critique": "",
        "report": "",
        "cycle_count": 0,
        "max_cycles": 1,
        "scenario_type": scenario_type,
        "enhancement_stats": None
    }
    
    config = RunnableConfig(
        configurable={
            "thread_id": f"research-{hash(query)}",
        }
    )
    
    final_state = None
    current_step = None  # è·Ÿè¸ªå½“å‰æ­¥éª¤
    
    # å®šä¹‰æ­¥éª¤é¡ºåºå’Œä¸‹ä¸€æ­¥æ˜ å°„
    step_order = ["research-planning", "information-gathering", "content-enhancement", "deep-analysis", "report-generation"]
    next_step_map = {
        "research-planning": "information-gathering",
        "information-gathering": "content-enhancement", 
        "content-enhancement": "deep-analysis",
        "deep-analysis": "report-generation",
        "report-generation": None  # æœ€åä¸€æ­¥
    }
    
    # ä½¿ç”¨è‡ªå®šä¹‰çš„printå‡½æ•°æ¥æ•è·STEP_INFO
    import sys
    from io import StringIO
    
    original_stdout = sys.stdout
    step_info_buffer = []
    
    class StepInfoCapture:
        def __init__(self, original_stdout):
            self.original_stdout = original_stdout
            self.buffer = ""
            
        def write(self, text):
            # å§‹ç»ˆè¾“å‡ºåˆ°æ§åˆ¶å°ï¼ˆä¿æŒæ—¥å¿—å¯è§ï¼‰
            self.original_stdout.write(text)
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«STEP_INFOå¹¶ç¼“å­˜
            if "STEP_INFO:" in text:
                lines = text.split('\n')
                for line in lines:
                    if line.strip().startswith("STEP_INFO:"):
                        step_info_buffer.append(line.strip())
            
        def flush(self):
            self.original_stdout.flush()
    
    try:
        # ä½¿ç”¨è‡ªå®šä¹‰çš„stdoutæ•è·å™¨
        sys.stdout = StepInfoCapture(original_stdout)
        
        # åˆ›å»ºV1å›¾å®ä¾‹
        v1_graph = build_graph()
        
        async for event in v1_graph.astream(initial_state, config):
            for node_name, node_data in event.items():
                if isinstance(node_data, dict):
                    final_state = node_data
                    
                    # æ ¹æ®èŠ‚ç‚¹åç§°æ›´æ–°currentStepå¹¶ç«‹å³å‘é€çŠ¶æ€
                    if node_name == "generate_queries":
                        current_step = "research-planning"
                    elif node_name == "web_search":
                        current_step = "information-gathering"
                    elif node_name == "content_enhancement":
                        current_step = "content-enhancement"
                    elif node_name == "reflect":
                        current_step = "deep-analysis"
                    elif node_name == "generate_report":
                        current_step = "report-generation"
                    
                    print(f"èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ: {node_name} -> currentStep: {current_step}")
                    
                    # ğŸ”¥ å‘é€ç”¨æˆ·å‹å¥½çš„æ­¥éª¤çŠ¶æ€
                    step_titles = {
                        "research-planning": "æ­£åœ¨æ·±åº¦ç ”ç©¶",
                        "information-gathering": "æ­£åœ¨æœé›†èµ„æ–™", 
                        "content-enhancement": "æ­£åœ¨æ·±åº¦åˆ†æ",
                        "deep-analysis": "æ­£åœ¨æ·±åº¦åˆ†æ",
                        "report-generation": "æ­£åœ¨ç”ŸæˆæŠ¥å‘Š"
                    }
                    
                    simple_status = {
                        "type": "step_update",
                        "step": current_step,
                        "currentStep": current_step,
                        "title": step_titles.get(current_step, f"æ­£åœ¨æ‰§è¡Œ{current_step}"),
                        "description": f"{step_titles.get(current_step, current_step)}é˜¶æ®µ",
                        "user_friendly": True
                    }
                    print(f"ğŸ“¡ å‘é€ç®€åŒ–çŠ¶æ€: {current_step}")
                    yield f"data: {json.dumps(simple_status, ensure_ascii=False)}\n\n"
                    
                    # å¼ºåˆ¶åˆ·æ–°ï¼Œç¡®ä¿æ•°æ®ç«‹å³å‘é€
                    await asyncio.sleep(0.01)
                    
                    # ğŸ”¥ æ¢å¤å®Œæ•´STEP_INFOå¤„ç†ï¼Œä½†ä¿®å¤currentStepé€»è¾‘
                    while step_info_buffer:
                        step_info_line = step_info_buffer.pop(0)
                        try:
                            json_str = step_info_line.split("STEP_INFO:", 1)[1].strip()
                            step_info = json.loads(json_str)
                            
                            # å…³é”®ä¿®å¤ï¼šæ ¹æ®æ­¥éª¤ç±»å‹å†³å®šcurrentStep
                            if step_info.get("type") == "step_complete":
                                # å¦‚æœæ˜¯æ­¥éª¤å®Œæˆï¼ŒcurrentStepåº”è¯¥æŒ‡å‘ä¸‹ä¸€ä¸ªæ­¥éª¤
                                step_name = step_info.get("step")
                                next_step = next_step_map.get(step_name)
                                if next_step:
                                    step_info["currentStep"] = next_step
                                    print(f"âœ… æ­¥éª¤å®Œæˆ: {step_name} -> currentStepè®¾ä¸ºä¸‹ä¸€æ­¥: {next_step}")
                                else:
                                    step_info["currentStep"] = step_name  # æœ€åä¸€æ­¥ä¿æŒä¸å˜
                                    print(f"âœ… æœ€åæ­¥éª¤å®Œæˆ: {step_name}")
                            else:
                                # å¦‚æœæ˜¯æ­¥éª¤å¼€å§‹æˆ–è¿›è¡Œä¸­ï¼ŒcurrentStepå°±æ˜¯å½“å‰æ­¥éª¤
                                step_info["currentStep"] = current_step
                            
                            print(f"ğŸ“¤ å‘é€æ­¥éª¤ä¿¡æ¯: step={step_info.get('step')}, currentStep={step_info.get('currentStep')}, type={step_info.get('type')}")
                            
                            # ç›´æ¥yieldå®Œæ•´çš„STEP_INFOï¼ˆä¿ç•™åŸæœ‰çš„è¯¦ç»†ä¿¡æ¯ï¼‰
                            yield f"data: {json.dumps(step_info, ensure_ascii=False)}\n\n"
                        except Exception as e:
                            print(f"è§£æSTEP_INFOå¤±è´¥: {e}")
                    
                    # å¦‚æœæœ‰æŠ¥å‘Šå†…å®¹ä¸”æ ‡è®°ä¸ºå®Œæˆï¼Œå‘é€å®Œæˆäº‹ä»¶
                    if node_data.get("report") and node_data.get("is_complete", False):
                        complete_data = {
                            "step": "complete", 
                            "report": node_data.get("report", ""),
                            "total_cycles": node_data.get("cycle_count", 1)
                        }
                        yield f"data: {json.dumps(complete_data, ensure_ascii=False)}\n\n"
                        return
            
            # å°å»¶è¿Ÿé¿å…è¿‡å¿«å‘é€
            await asyncio.sleep(0.1)
        
        # å¤„ç†å‰©ä½™çš„STEP_INFO
        while step_info_buffer:
            step_info_line = step_info_buffer.pop(0)
            try:
                json_str = step_info_line.split("STEP_INFO:", 1)[1].strip()
                step_info = json.loads(json_str)
                
                # åŒæ ·å¤„ç†å‰©ä½™çš„STEP_INFO
                if step_info.get("type") == "step_complete":
                    step_name = step_info.get("step")
                    next_step = next_step_map.get(step_name)
                    if next_step:
                        step_info["currentStep"] = next_step
                    else:
                        step_info["currentStep"] = step_name
                
                yield f"data: {json.dumps(step_info, ensure_ascii=False)}\n\n"
            except Exception as e:
                print(f"è§£ææœ€ç»ˆSTEP_INFOå¤±è´¥: {e}")
        
        # å›¾æ‰§è¡Œå®Œæ¯•åçš„æœ€ç»ˆæ£€æŸ¥
        if final_state and final_state.get("report") and not final_state.get("is_complete"):
            complete_data = {
                "step": "complete",
                "report": final_state.get("report", ""),
                "total_cycles": final_state.get("cycle_count", 1)
            }
            yield f"data: {json.dumps(complete_data, ensure_ascii=False)}\n\n"
            
    except Exception as e:
        error_data = {"step": "error", "details": str(e)}
        yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
    finally:
        # æ¢å¤åŸå§‹stdout
        sys.stdout = original_stdout


@app.post("/research")
async def research(request: ResearchRequest):
    """
    V1ç ”ç©¶ç«¯ç‚¹ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
    æ‰§è¡ŒåŸºç¡€çš„å¤šè½®æœç´¢å’ŒæŠ¥å‘Šç”Ÿæˆ
    """
    print(f"ğŸ“¡ æ”¶åˆ°V1ç ”ç©¶è¯·æ±‚ï¼š{request.query} (åœºæ™¯ï¼š{request.scenario_type})")
    
    if not request.query.strip():
        raise HTTPException(status_code=400, detail="æŸ¥è¯¢ä¸èƒ½ä¸ºç©º")
    
    return StreamingResponse(
        stream_research_v1(request.query, request.scenario_type),
        media_type="text/plain; charset=utf-8",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
            "Access-Control-Allow-Headers": "Content-Type",
        }
    )


# ===== V1.5 å¿«é€Ÿæœç´¢API =====

# é›†æˆå¿«é€Ÿæœç´¢ç«¯ç‚¹ - ç”¨äºåŸºç¡€å¯¹è¯å¢å¼º
create_quick_search_endpoints(app)


# ===== V2 APIï¼ˆæ–°çš„ç»Ÿä¸€æ¶æ„ï¼‰ =====

# é›†æˆç»Ÿä¸€APIç«¯ç‚¹
create_unified_research_endpoint(app)


# ===== é€šç”¨ç«¯ç‚¹ =====

@app.get("/")
async def root():
    """APIæ ¹ç«¯ç‚¹"""
    return {
        "message": "LangGraph Research API",
        "version": "2.0.0",
        "description": "æ”¯æŒV1.5å’ŒV2ä¸¤ç§æ¶æ„çš„æ™ºèƒ½ç ”ç©¶API",
        "endpoints": {
            "v1.5": "/research - å¢å¼ºç ”ç©¶æ¶æ„ (å«Firecrawl)",
            "v2": "/unified-research - é«˜çº§æ™ºèƒ½æ¶æ„",
            "quick_search": "/api/quick-search - å¿«é€Ÿæœç´¢ (æ”¯æŒå¯¹è¯å¢å¼º)",
            "versions": "/research-versions - è·å–æ”¯æŒçš„ç‰ˆæœ¬ä¿¡æ¯"
        }
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "healthy",
        "v1_available": True,
        "v2_available": True,
        "timestamp": "now"
    }


@app.get("/api-info")
async def api_info():
    """APIä¿¡æ¯ç«¯ç‚¹"""
    return {
        "api_version": "2.0.0",
        "supported_architectures": [
            {
                "version": "v1.5",
                "name": "å¢å¼ºç ”ç©¶æ¶æ„",
                "endpoint": "/research",
                "features": ["å¤šè½®æœç´¢", "Firecrawlå†…å®¹å¢å¼º", "æ™ºèƒ½åæ€", "æŠ¥å‘Šç”Ÿæˆ"],
                "scenarios": ["simple", "adaptive", "complex"],
                "new_in_v1_5": ["æ·±åº¦å†…å®¹æŠ“å–", "URLè´¨é‡ç­›é€‰", "å¢å¼ºç»Ÿè®¡æŠ¥å‘Š"]
            },
            {
                "version": "v2",
                "name": "é«˜çº§æ™ºèƒ½æ¶æ„", 
                "endpoint": "/unified-research",
                "features": ["æ™ºèƒ½è§„åˆ’", "å¤šä»»åŠ¡åè°ƒ", "å†…å®¹å¢å¼º", "å¹¶è¡Œå¤„ç†"],
                "modes": ["research_assistant", "quick_lookup", "deep_research"]
            }
        ],
        "quick_search_api": {
            "endpoint": "/api/quick-search",
            "purpose": "ä¸ºåŸºç¡€å¯¹è¯æä¾›ä¿¡æ¯æ£€ç´¢å¢å¼º",
            "features": ["å¿«é€Ÿç½‘ç»œæœç´¢", "å¯é€‰Firecrawlå¢å¼º", "æ™ºèƒ½æ‘˜è¦ç”Ÿæˆ"],
            "use_cases": ["DeepSeekç­‰æ¨¡å‹å¢å¼º", "å®æ—¶ä¿¡æ¯æŸ¥è¯¢", "å¯¹è¯ä¸Šä¸‹æ–‡è¡¥å……"]
        },
        "environment": {
            "gemini_api_configured": bool(os.getenv("GEMINI_API_KEY")),
            "google_search_configured": bool(os.getenv("GOOGLE_API_KEY"))
        }
    }


if __name__ == "__main__":
    import uvicorn
    
    print("ğŸŒŸ å¯åŠ¨LangGraph Research APIæœåŠ¡å™¨")
    print("ğŸ“‹ æ”¯æŒçš„åŠŸèƒ½ï¼š")
    print("  âœ… V1æ¶æ„ï¼šç»å…¸å¤šè½®æœç´¢")
    print("  ğŸš€ V2æ¶æ„ï¼šæ™ºèƒ½å¤šä»»åŠ¡ç ”ç©¶")
    print("  ğŸ”„ æµå¼å“åº”")
    print("  ğŸŒ CORSæ”¯æŒ")
    
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    ) 